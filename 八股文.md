# 编程基础知识

## 1. 什么是**面向对象编程**？

面向过程：注重解决过程，以函数和数据（即用于方法的参数）为主按照顺序执行方法。

面向对象编程是一种以对象为中心的编程思想，将程序中的数据和操作封装在一个对象中。在OOP中，程序是由一系列的对象组成的，每个对象都有自己的属性和方法。

具有封装、继承和多态等特点，易于维护、可扩展性好和代码重用性高。

## 2. 面向对象三大特性**封装、继承、多态**如何理解？

**封装：**

它指的是将数据和操作数据的代码放在一起，形成对象。

封装有两个重要的结果：一是避免外部代码直接访问对象内部的细节；二是可以对内部的数据和方法进行保护，通过权限控制提升安全性。这通过在类定义中设定公共（public）、私有（private）和保护（protected）成员来实现。

**继承：**

**继承使得类可以派生出新的子类**，从而继承父类的属性和行为，并增加或者改变一些现有的功能。继承提供了代码重用的能力，这意味着可以创建通用的父类，然后构建更具体的子类来满足不同的需求。在OOP中，类的继承通常体现了一个“是”关系，例如，“猫是动物”，所以猫类可以从动物类中继承。

继承方式包括 public（公有的）、private（私有的）和 protected（受保护的），此项是可选的，如果不写，那么默认为 private。基类成员在派生类中的访问权限不得高于继承方式中指定的权限。

继承的一般语法为：

class 派生类名:［继承方式］ 基类名{

  派生类新增加的成员

};

**多态：**

1. 定义：

 多态意味着调用成员函数时，会根据调用函数的对象的类型来执行不同的函数。这使得程序更加灵活，可以通过引用父类来操作不同子类的对象。

2. 多态的实现主要分为静态多态和动态多态。

静态多态：重载(overload)：编译器在编译期间完成的；主要通过函数和运算符重载来实现。允许存在多个同名函数，而函数的参数列表不同。

动态多态：函数入口地址是在运行阶段确定；主要通过继承和虚函数来实现。子类重新定义父类的虚函数。

## 3. 重载与重写的区别与联系？

**重载**(overload)：**联系**：函数名字相同；**区别**：相同的范围（在同一个类中)；参数不同；返回类型可相同可不同；virtual关键字可有可无。 

**覆盖/重写**(override)是指派生类函数覆盖基类函数，特征是： 

**联系**：函数名字相同；**区别**：不同的范围（分别位于派生类（子类）与基类（父类））；参数相同；返回类型相同；基类（父类）函数必须有virtual关键字。

## 4. 类普通成员函数、构造函数和类静态成员函数的区别？

py的问法：类方法、类实例方法和类静态方法的区别？

* **构造函数**：是类的一种特殊的成员函数，它会在每次创建类的新对象时执行。构造函数的名称与类的名称是完全相同的，并且不会返回任何类型，也不会返回 void。构造函数可用于为某些成员变量设置初始值。
* 类的成员函数：是指那些把定义和原型写在类定义内部的函数；

* 静态成员函数：类体中的成员函数的声明前加上static关键字。

1. 生成时机
   静态成员函数在编译的时候就已经加载了并分配了内存;

   因此调用静态成员函数速度快，但是会占用内存。

2. 调用方式

   普通成员函数：先创建类的对象，才能进行调用（对象.方法（））。

   静态成员函数：类名加范围解析运算符 **::** 就可以访问，不需要先创建类的对象。（类.静态方法（））

3. 访问限制

   普通成员函数：有 this 指针，可以使用成员函数来访问类中的任意成员；

   静态成员函数：没有 this 指针，只能访问静态成员（包括静态成员变量和静态成员函数）；

```c++
class Test {
    public:
    void non_static_fuc() {
        // 实现略
    }
    static static_func() {
        // 实现略
    }
};
// 非静态方法的使用，必须通过对象调用
Test obj;
obj.non_static_fucn(); // 调用非静态方法
// 静态方法既可以通过对象调用，也可以通过类名调用
obj.static_func();   // 通过对象调用
Test::static_func(); //  通过类名调用
```

## 5. 全局变量和局部变量有什么区别和联系？

* 局部变量：使用范围：在函数内部或代码块中定义的变量，只能在函数内部使用；

​			   生命周期：函数执行结束后，函数内部的局部变量，会被系统回收；

* 全局变量：使用范围：在函数外部定义的变量（没有定义在某一个函数内)，所有函数都能访问；

  ​                   生命周期：程序一启动就会分配存储空间，直到程序结束才会释放。

修改：如果在函数内部中需要修改全局变量，需要使用global进行声明。

## 6. 成员变量和局部变量有什么区别和联系？

* 成员变量：存在类中声明的；成员变量只能通过对象访问；存储 ：栈中；注：成员变量在定义的同时不能初始化。

* 局部变量范围：写在函数或代码块中的变量；作用域: 从定义的那一行开始, 一直到遇到大括号或者return
  存储 : 栈；

  存储在栈中数据有一个特点, 系统会自动给我们释放

补充：
1、变量分为全局变量、静态全局变量、局部变量、静态局部变量
2、变量存在的两个属性：作用域和存储类别

外部变量(全局变量)、静态外部变量（全局变量）、静态局部变量存储在静态存储区；注：常量也在静态存储区

自动局部变量（局部变量默认为自动局部变量）、函数形参存储在动态存储区（即栈区）；

不论是静态存储区还是动态存储区均属于内存中的用户区；

而寄存器变量是存储在CPU寄存器中的而不是内存中；

3、与存储类型相关的几个属性：

atuo：在声明局部变量时，若不指定static，默认均是auto，这类变量都是动态分配存储空间的，数据存储在栈中；

static：在声明局部变量时，使用关键字static 将局部变量指定为“静态局部变量”，这样在函数调用结束后不消失而保留原值，即占用的存储单元不释放，在下一次函数调用时，该变量已有值就是上次函数调用结束时的值；

register：在声明动态局部变量或者函数形参时，可将变量声明为register，这样编译系统就会为变量分配一个寄存器而不是内存空间，通过这种方式可提升对某些局部变量频繁调用的程序的性能。(寄存器运算速度远高于内存)；

extern：用于扩展全局变量的作用域；

比如如果函数想引用一个外部变量，但该外部变量在该函数后定义，那么这个函数需要使用extern 来声明变量，这样才能使用在该函数后面定义的全局变量。

此外，extern 还可以在多文件的程序中声明外部变量。
## 7. 什么是抽象类？抽象类和普通类有什么区别和联系？

* 抽象类

抽象类是特殊的类，不能被实例化（将定义了纯虚函数的类称为抽象类）；除此以外，具有类的其他特性；

重要的是抽象类可以包括抽象方法，这是普通类所不能的，但同时也能包括普通的方法。

抽象方法只能声明于抽象类中，且不包含任何实现，派生类必须覆盖/重写它们。
另外，抽象类可以派生自一个抽象类，可以覆盖基类的抽象方法也可以不覆盖，如果不覆盖，则其派生类必须覆盖它们。
虽然不能定义抽象类的实例，但是可以定义它的指针，这正是用抽象类实现接口的重点所在。

含有抽象方法的类就叫抽象类。而抽象方法就是被abstract修饰的方法，这个方法可以没有具体的实现。

在抽象类的子类中必须对抽象方法进行重写，当其子类为抽象类时，可以不重写抽象方法，但在其子类中一旦有普通类，则必须重写父类继承的所有抽象方法。

抽象类不可以实例化。抽象类的构造方法作用为初始化子类对象。

抽象类存在的意义就是为了被继承。

抽象类中的普通属性和普通方法都需要用子类的对象去调用。

* 普通类和抽象类的区别总结

1、抽象类必须用abstract来修饰，普通类则不用

2、抽象类的存在时为了被继承，不能实例化，而普通类存在是为了实例化一个对象

3、抽象类的子类必须重写抽象类中的抽象方法，而普通类可以选择重写父类的方法，也可以直接调用父类的方法

4、普通类和抽象类都可以含有普通成员属性和普通方法

5、普通类和抽象类都可以继承别的类或者被别的类继承

6、普通类和抽象类的属性和方法都可以通过子类对象来调用

## 8. 什么是接口？接口和抽象类之间有什么区别和联系？

接口描述了类的行为和功能，而不需要完成类的特定实现。

C++ 接口是使用**抽象类**来实现的，抽象类与数据抽象互不混淆，数据抽象是一个把实现细节与相关的数据分离开的概念。

如果类中至少有一个函数被声明为纯虚函数，则这个类就是抽象类。纯虚函数是通过在声明中使用 "= 0" 来指定的，如下所示：

```c++
class Box
{
   public:
      // 纯虚函数
      virtual double getVolume() = 0;
   private:
      double length;      // 长度
      double breadth;     // 宽度
      double height;      // 高度
};
```

设计**抽象类**（通常称为 ABC）的目的，是为了给其他类提供一个可以继承的适当的基类。抽象类不能被用于实例化对象，它只能作为**接口**使用。如果试图实例化一个抽象类的对象，会导致编译错误。

因此，如果一个 ABC 的子类需要被实例化，则必须实现每个纯虚函数，这也意味着 C++ 支持使用 ABC 声明接口。如果没有在派生类中重写纯虚函数，就尝试实例化该类的对象，会导致编译错误。

可用于实例化对象的类被称为**具体类**。

**抽象类的实例**

请看下面的实例，基类 Shape 提供了一个接口 **getArea()**，在两个派生类 Rectangle 和 Triangle 中分别实现了 **getArea()**：

```c++
#include <iostream>
using namespace std;
 
// 基类
class Shape 
{
public:
   // 提供接口框架的纯虚函数
   virtual int getArea() = 0;
   void setWidth(int w)
   {
      width = w;
   }
   void setHeight(int h)
   {
      height = h;
   }
protected:
   int width;
   int height;
};
 
// 派生类
class Rectangle: public Shape
{
public:
   int getArea()
   { 
      return (width * height); 
   }
};
class Triangle: public Shape
{
public:
   int getArea()
   { 
      return (width * height)/2; 
   }
};
 
int main(void)
{
   Rectangle Rect;
   Triangle  Tri;
 
   Rect.setWidth(5);
   Rect.setHeight(7);
   // 输出对象的面积
   cout << "Total Rectangle area: " << Rect.getArea() << endl;
 
   Tri.setWidth(5);
   Tri.setHeight(7);
   // 输出对象的面积
   cout << "Total Triangle area: " << Tri.getArea() << endl; 
 
   return 0;
}
```

## 9. 什么是流？输入流和输出流的区别是什么？

* 流：

它是一种数据传输的模式。根据数据流方向的不同，可分为输入流和输出流。

* 输入流和输出流的区别：

输入流就是把数据（键盘输入、鼠标、扫描仪等等外设设备）读入到内存（程序）中，

输出流就是把内存（程序）中的数据输出到外设或其他地方，

从文件角度简单总结就是，输入流就是读数据，输出流就是写数据。在这个过程中，始终把内存作为参考点。

# C++

## 1. C和C++的区别和联系是什么？

设计思想：C++是面向对象的语言，而C是面向过程的结构化编程语言。

1. 头文件：C++中用来做控制态输入输出的iostream类库替代了标准C中的stdio函数库。

2. 数据类型：标准C++中的字符串类取代了标准C函数库头文件中的字符数组处理函数（C中没有字符串类型）。

函数：

3. C++中new和delete是对内存分配的运算符，取代了C中的malloc和free。

4. C++中的try/catch/throw异常处理机制取代了标准C中的setjmp()和longjmp()函数。

5. 在C++中，允许有相同的函数名，不过它们的参数类型不能完全相同，这样这些函数就可以相互区别开来。而这在C语言中是不允许的。也就是C++可以**重载**，C语言不允许。

6. 引用：在C++中，除了值和指针之外，新增了引用。引用型变量是其他变量的一个别名，我们可以认为他们只是名字不相同，其他都是相同的。

7. 关键字：C++相对与C增加了一些关键字，如：bool、using、dynamic_cast、namespace等等

## 2. C中的结构体和C++中的类有什么区别和联系？

1、默认访问权限：struct默认的数据访问控制是public的，class默认的成员变量访问控制是private的；

2、方法：C语言的结构体只能包含数据成员，而C++的类除了数据成员外，还可以包含成员函数（方法）；

3、继承：C++的类支持继承的概念，可以通过派生类继承基类的成员和行为。而在C语言中，结构体没有直接的继承机制。

## 3. C++中，宏定义`#define`和关键字`const`、关键字`typedef`有什么区别？

**define：**1. 主要用于定义常量及书写复杂的内容；2. 宏替换发生在编译阶段之前，属于文本插入替换；3. 宏不检查类型；4. 宏不是语句，不再在最后加分号；5. define 定义的宏常量，在程序中使用多少次就会进行多少次替换，内存中有多个备份，占用的是代码段的空间；

**typedef：**1. 主要用于定义类型别名；2. typedef是编译的一部分；3. typedef会检查数据类型；4. typedef是语句，要加分号标识结束

 **const ：**2. const 是在编译阶段确定其值；3. const 定义的常量是有类型的，是要进行判断的；4. typedef是语句，要加分号标识结束；5. 内存：const 定义的常量占用静态存储区的空间，程序运行过程中只有一份；

**例题**：注意对指针的操作，typedef char * p_char和#define p_char char *区别巨大：

`typedef char * p_char` 创建了一个类型别名 `p_char`，将 `char *` 类型命名为 `p_char`，可以在其作用域内使用该类型别名。而 `#define p_char char *` 定义了一个宏 `p_char`，将 `p_char` 在预处理阶段进行简单的文本替换，将其替换为 `char* `。在使用宏定义时应该小心，避免出现意外的副作用。而 `typedef` 则提供了更安全和可控的方式来创建类型别名。

## 4. C++中，函数`sizeof()`和函数`strlen()`有什么区别？

1、`sizeof`是一个运算符；`strlen`是字符处理的库函数。

2、`sizeof()` 可以用于任何类型的数据，而 `strlen()` 只能用于以空字符 '\0' 结尾的字符串。

3、`sizeof()` 计算的是变量或类型所占用的内存字节数，而 `strlen()` 计算的是字符串中字符的个数。

4、计算字符串的长度时：`sizeof()` 包含末尾的 '\0'，strlen() 计算字符串的长度，不包含字符串末尾的 '\0'。

5、因为`sizeof`值在编译时确定，所以不能用来得到动态分配（运行时分配）存储空间的大小。

```c++
#include <iostream>
#include <cstring>
using namespace std;

int main()
{
    char *str = "name";
    cout<<sizeof(str)<<endl; // 取的是指针str的长度，是8
    cout<<strlen(str)<<endl; // 取的是这个字符串的长度，不包含结尾的 \0。大小是4
    char s[] = "name";
    cout<<sizeof(s)<<endl; // 5
    cout<<strlen(s)<<endl; // 4，string s编译出错
    return 0;
}
```

## 5. C++的内存管理中，**堆区和栈区**的区别和联系是什么？

- 管理方式
- 使用方式和寿命
- 应用场景举例



- 申请方式不同：

  栈由系统自动分配；堆是自己申请和释放的。

- 申请方向大小不同：

  栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过ulimit -a查看，由ulimit -s修改。

  堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。

   栈空间默认是4M, 堆区一般是 1G - 4G 

- 申请效率不同：

  栈由系统分配，速度快，不会有碎片。

  堆由程序员分配，速度慢，且会有碎片。

|                  | 堆                                                           | 栈                                                           |
| :--------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **管理方式**     | 堆中资源由程序员控制（容易产生memory leak）                  | 栈资源由编译器自动管理，无需手工控制                         |
| **内存管理机制** | 系统有一个记录空闲内存地址的链表，当系统收到程序申请时，遍历该链表，寻找第一个空间大于申请空间的堆结点，删    除空闲结点链表中的该结点，并将该结点空间分配给程序（大多数系统会在这块内存空间首地址记录本次分配的大小，这样delete才能正确释放本内存空间，另外系统会将多余的部分重新放入空闲链表中） | 只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报异常提示栈溢出。（这一块理解一下链表和队列的区别，不连续空间和连续空间的区别，应该就比较好理解这两种机制的区别了） |
| **空间大小**     | 堆是不连续的内存区域（因为系统是用链表来存储空闲内存地址，自然不是连续的），堆大小受限于计算机系统中有效的虚拟内存（32bit  系统理论上是4G），所以堆的空间比较灵活，比较大 | 栈是一块连续的内存区域，大小是操作系统预定好的，windows下栈大小是2M（也有是1M，在  编译时确定，VC中可设置） |
| **碎片问题**     | 对于堆，频繁的new/delete会造成大量碎片，使程序效率降低       | 对于栈，它是有点类似于数据结构上的一个先进后出的栈，进出一一对应，不会产生碎片。（看到这里我突然明白了为什么面试官在问我堆和栈的区别之前先问了我栈和队列的区别） |
| **生长方向**     | 堆向上，向高地址方向增长。                                   | 栈向下，向低地址方向增长。                                   |
| **分配方式**     | 堆都是动态分配（没有静态分配的堆）                           | 栈有静态分配和动态分配，静态分配由编译器完成（如局部变量分配），动态分配由alloca函数分配，但栈的动态分配的资源由编译器进行释放，无需程序员实现。 |
| **分配效率**     | 堆由C/C++函数库提供，机制很复杂。所以堆的效率比栈低很多。    | 栈是其系统提供的数据结构，计算机在底层对栈提供支持，分配专门  寄存器存放栈地址，栈操作有专门指令。 |

**形象的比喻**

栈就像我们去饭馆里吃饭，只管点菜（发出申请）、付钱、和吃（使用），吃饱了就走，不必理会切菜、洗菜等准备工作和洗碗、刷锅等扫尾工作，他的好处是快捷，但是自由度小。

堆就象是自己动手做喜欢吃的菜肴，比较麻烦，但是比较符合自己的口味，而且自由度大。

### **为什么栈比堆快？**

因为操作系统会在底层对栈提供支持，会分配专门的寄存器存放栈的地址，栈的入栈出栈操作也十分简单，并且有专门的指令执行，所以栈的效率比较高也比较快。

而堆的操作是由C/C++函数库提供的，在分配堆内存的时候需要一定的算法寻找合适大小的内存。并且获取堆的内容需要两次访问，第一次访问指针，第二次根据指针保存的地址访问内存，因此堆比较慢。

## 6. C++中，**内存的分配方式**有哪几种？

C++中的内存分区，分别是堆、栈、自由存储区、全局/静态存储区、常量存储区和代码区。如下图所示：

![](http://oss.interviewguide.cn/img/202205220021689.png)

**栈**：在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。

**堆**：就是那些由 `new`分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个`new`就要对应一个 `delete`。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。

**全局/静态存储区**：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量和静态变量又分为初始化的和未初始化的，在C++里面没有这个区分了，它们共同占用同一块内存区，在该区定义的变量若没有初始化，则会被自动初始化，例如int型变量自动初始为0。

**常量存储区**：这是一块比较特殊的存储区，这里面存放的是常量，不允许修改。

**自由存储区**：如果说堆是操作系统维护的一块内存，那么自由存储区就是C++中通过new和delete动态分配和释放对象的抽象概念。需要注意的是，自由存储区和堆比较像，但不等价。

**代码区**：存放函数体的二进制代码

## 7. C++中，什么是内存泄漏？**内存泄漏**的场景有哪些？

在C++中，内存泄漏是指程序在动态分配内存后，没有释放该内存，导致程序在运行过程中持续消耗内存，直到程序结束才会释放，这会导致系统内存资源的浪费。

内存泄漏的场景包括但不限于以下几种：

1. **忘记释放动态分配的内存**：在使用 `new` 关键字分配内存后，没有使用 `delete` 或 `delete[]` 来释放内存。
 ```C++
 intptr = new int;
 // 没有释放内存，导致内存泄漏
 ```

2. **指针指向错误的内存地址**：当指针指向了一个错误的内存地址，而没有释放该内存。

```C++
int ptr = nullptr;
{
    int val = 10;
    ptr = &val;
}
// 此时 ptr 指向了一个已经销毁的变量 val，但是没有释放该内存,ptr成为悬挂指针
```

3. **智能指针循环引用**：在使用智能指针时，如果存在循环引用，即两个对象互相持有对方的智能指针，会导致对象间的内存无法被释放。

```C++
class Node {
public:
    shared_ptr<Node> next;
};
shared_ptr<Node> node1 = make_shared<Node>();
shared_ptr<Node> node2 = make_shared<Node>();
node1->next = node2;
node2->next = node1;
// node1 和 node2 会一直持有对方的引用，导致内存泄漏4
```

4. **异常情况下未释放内存**：如果在程序执行过程中发生了异常，并且没有在异常处理代码中释放内存，也会导致内存泄漏。

```C++
void foo() {
    intptr = new int;
    throw "Error occurred";
    delete ptr; // 没有机会执行到这里，导致内存泄漏
}
```

5. **多次释放相同的内存**：如果多次释放相同的内存，会导致程序崩溃或者不可预测的行为。

```C++
intptr = new int;
delete ptr;
delete ptr; // 尝试释放已经释放过的内存，导致不可预测的行为
```

注意：使用智能指针（如 `std::shared_ptr`、`std::unique_ptr`）可以有效地避免内存泄漏问题，因为它们会在对象不再需要时自动释放内存。

## 8. 野指针是什么？如何避免产生野指针？

1. 野指针是未初始化的指针。野指针不能判断是否为NULL来避免。

2. 原因？如何避免？

   指针变量未初始化 $\Rightarrow$​ 指针变量及时初始化或初始化为nullptr。

   ```
   ```

   


### 悬挂指针：

1. 当所指向的对象被释放或者收回，但是对该指针没有作任何的修改，以至于该指针仍旧指向已经回收的内存地址。

2. 原因？如何避免

   指针free或delete后没有及时置空  $\Rightarrow$ 释放操作后及时置空。

```c++
int main()
{
	int *p; // 野指针
    int *p2 = nullptr; // nullptr表示不指向任何有效内存，为悬空指针
    int *p3 = new int;
    p2 = p3;
    delete p3; // 悬空指针
    return 0;
}
```

智能指针解决悬挂指针。

## 9. C++中，静态内存分配和动态内存分配有什么区别和联系？

   1、时间不同：静态分配发生在程序编译和连接的时候；动态分配则发生在程序调入和执行的时候。

   2、存储位置：静态内存分配使用静态存储区，用于存储全局变量、静态变量和局部静态变量。  动态内存分配使用堆（Heap），用于存储动态分配的对象和数据。

3. 生命周期：静态分配的内存在程序整个生命周期内都存在，不会在运行时被创建或销毁。动态分配的内存在手动释放之前一直存在，可以在程序的任意时间点进行分配和释放。
4. 分配和释放：静态内存分配由编译器自动完成，无需手动释放内存。动态内存分配需要手动进行，通过使用特定的操作符和函数（如`new`和`delete`、`malloc`和`free`等）来分配和释放内存。

## 10. 关键字`new`和函数`malloc()`有什么区别和联系？

## 11. 关键字`delete`和函数`free()`有什么区别和联系？

* **相同点**：都可用于内存的动态申请和释放。

* **区别**：

1.属性：new/delete是C++关键字，需要编译器支持。malloc/free是库函数，需要头文件支持。

2.参数：使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。而malloc则需要显式地指出所需内存的尺寸。

3.分配成功/失败：new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符；new内存分配失败时，会抛出bac_alloc异常。

malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。malloc分配内存失败时返回NULL。

5.自定义类型：new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现；然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。   malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。

6.重载：C++允许重载new/delete操作符，特别地，布局new的就不需要为对象分配内存，而是指定了一个地址作为内存起始区域，new在这段内存上为对象调用构造函数完成初始化工作，并返回此地址。而malloc不允许重载。

1、free既可以在C语言中使用也可以在C++中使用，delete只能在C++中使用。

2、free只释放malloc所开辟的内存空间，delete自动调用对象的析构函数析构对象并释放new所开辟的内存空间。

3、free只能和malloc搭配使用，如果和new搭配编译不通过；delete既能跟malloc搭配使用，又能和new搭配使用，但由于和malloc搭配使用可读性太差，所以不建议使用delete搭配malloc。

### 既然有了malloc/free，C++中为什么还需要new/delete呢？直接用malloc/free不好吗？

* malloc/free和new/delete都是用来申请内存和回收内存的。
* 在对非基本数据类型的对象使用的时候，对象创建的时候还需要执行构造函数，销毁的时候要执行析构函数。而malloc/free是库函数，是已经编译的代码，所以不能把构造函数和析构函数的功能强加给malloc/free，所以new/delete是必不可少的。

## 12. C++中的**指针和引用**分别是什么？它们有什么区别？

1. 属性：指针是一个变量，存储的是一个地址；引用是原变量的别名，跟原来的变量实质上是同一个东西；

2. 初始化：指针可以为空，引用不能为NULL且在定义时必须初始化；

   指针在初始化后可以改变指向，而引用在初始化之后不可再改变（变量可以被引用为多次，但引用只能作为一个变量引用）

3. 不存在指向空值的引用，必须有具体实体；但是存在指向空值的指针。
4. 级数：指针可以有多级，引用只有一级；
5. sizeof指针得到的是本指针的大小，sizeof引用得到的是引用所指向变量的大小
6. 当把指针作为参数进行传递时，也是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，在函数中改变这个变量的指向不影响实参，而引用却可以。

参考代码：

```cpp
void test(int *p)
{
　　int a=1;
　　p=&a;
　　cout<<p<<" "<<*p<<endl;
}

int main(void)
{
    int *p=NULL;
    test(p);
    if(p==NULL)
    cout<<"指针p为NULL"<<endl;
    return 0;
}
//运行结果为：
//0x22ff44 1
//指针p为NULL


void testPTR(int* p) {
	int a = 12;
	p = &a;
}

void testREFF(int& p) {
	int a = 12;
	p = a;
}
void main()
{
	int a = 10;
	int* b = &a;
	testPTR(b);//改变指针指向，但是没改变指针的所指的内容
	cout << a << endl;// 10
	cout << *b << endl;// 10

	a = 10;
	testREFF(a);
	cout << a << endl;//12
}
```

 在编译器看来, int a = 10; int &amp;b = a; 等价于 int * const b = &amp;a; 而 b = 20; 等价于 *b = 20; 自动转换为指针和自动解引用. 

## 13. C++中，`a`和`&a`有什么区别和联系？

假设数组int a[10]; int (*p)[10] = &a; 其中：

1. a是数组名，是数组首元素地址，+1表示地址值加上一个int类型的大小，如果a的值是0x00000001，加1操作后变为0x00000005。*(a + 1) = a[1]。

2. &a是整个数组地址，数组的指针，其类型为int (*)[10]（就是前面提到的数组指针），其加1时，系统会认为是数组首地址加上整个数组的偏移（10个int型变量），值为数组a尾元素后一个元素的地址。

   若(int *)p ，此时输出 *p时，其值为a[0]的值，因为被转为int *类型，解引用时按照int类型大小来读取。

## 14. C++中，**数组名和指向数组首元素的指针**有什么区别和联系？

```c++
#include <iostream>
using namespace std;
int main() {
    int a[5] = {1, 2, 3, 4, 5}; // a：数组名 
    cout << a << endl; // 第一个元素地址，&a[0]
    cout << &a << endl; // 整个数组地址
    
    int* p = a;  // 创建一个指向数组首元素的指针
    for (int i = 0; i < 5; i++) {
        std::cout << *p << " ";  // 输出指针指向的元素值
        p++;  // 指针移动到下一个元素
    }
    
   	int (*p2)[10] = &a; // 指向整个数组的指针
    for (int i=0; i<10; i++)
        std::cout << (*p2)[i] << " ";
    
    int *p3[10] = a; // 数组指针
    for (int i=0; i<10; i++)
        p3[i] = &a[i]; // 每个元素为数组a元素地址
    return 0;
}
```

1. 区别：
   1. 类型不同：数组名是一个常量指针，指向数组的首地址，并且不能被重新赋值；而指向数组首元素的指针是一个普通指针，可以被重新赋值指向其他地址。
   2. 用法不同：数组名在大多数情况下会隐式转换为指向数组首元素的指针，但是在某些情况下有特殊的语义，比如 `sizeof` 操作符中；而指向数组首元素的指针需要显式地取得，可以进行指针运算和递增/递减操作。
2. 联系：
   1. 地址相同：数组名和指向数组首元素的指针都存储了数组的首地址，因此它们的值是相同的。
   2. 指向同一元素：数组名和指向数组首元素的指针都指向数组的第一个元素，即它们在初始时的值是相同的。
   3. 使用场景：数组名和指向数组首元素的指针都可以用于访问数组中的元素，进行指针运算和数组操作。通常情况下，更推荐使用指向数组首元素的指针来进行数组的操作，因为它更灵活，并且可以与指针相关的其他特性一起使用。

## 15. C++中，`NULL`和`nullptr`有什么区别和联系？

在C++中，`NULL` 是一个宏定义，通常被定义为整数 0，用于表示空指针。

`nullptr` 是 C++11 引入的关键字，用于表示空指针常量。

区别如下：

1. 类型安全性：
   1. `NULL` 是整数 0，在一些情况下，可能会被隐式转换为其他类型指针，存在类型不安全的风险。
   2. `nullptr` 是空指针常量，其类型是 `std::nullptr_t`，可以隐式转换为任何指针类型，但是无法隐式转换为整数类型，从而提供了更好的类型安全性。
2. 上下文：
   1. `NULL` 是一个宏定义，属于 C 语言的一部分，可以在 C 和 C++ 中使用。
   2. `nullptr` 是 C++11 引入的新关键字，只能在支持 C++11 标准的编译器中使用。

一般情况下，建议在 C++ 中使用 `nullptr` 表示空指针，它能提供了更好的类型安全性和可移植性。

## 16. C++标准模板库STL中，`vector`容器是什么？它具有什么特点？

1. 是什么？

   向量（Vector）是数组的一种类表示，向量是一个能够存放任意类型的动态数组。

2. 特点：

   1. 顺序序列

   顺序容器中的元素按照严格的线性顺序排序。可以通过元素在序列中的位置访问对应的元素。

   2. 动态数组

   提供自动内存管理的功能，能动态改变vector对象长度，并随着元素的添加和删除而增加和缩小。

   3. 时间复杂度

   在尾部添加和删除元素的时间是固定的，但在头部或中间插入和删除元素的时间复杂度为线性。

   4. 可反转容器

   提供了rbegin()和rend()，前者返回指向反转序列的第一个元素的迭代器，后者返回反转序列的超尾迭代器。

## 17. 当`vector`空间不足时，如何实现扩容？

vector一次性分配好内存，不够时才进行2倍扩容。

## 18. C++标准模板库STL中，`unordered_map`和`map`有什么区别和联系？

**联系：**

都是将值与键关联起来，并使用键来查找值。

**区别：**

1. 有序：unordered_map是无序的，map是内部自动排序；

2. 底层差别：关联容器是基于树的结构，无序关联容器基于数据结构哈希表，旨在提高添加和删除元素的速度和查找元素的效率。


###  **哈希表的底层原理**是怎么实现的？

unordered_map 的底层实现是一个哈希表，每个元素由一个键值对组成。键是唯一的，而值可以是任何类型。在插入元素时，unordered_map 会计算键的哈希值，并使用这个哈希值在哈希表中定位一个槽位。如果两个键的哈希值相同（哈希冲突），开链法：那么它们的键值对将被放在同一个槽位中，形成一个链表。查找操作首先计算键的哈希值，然后直接定位到对应的槽位，并在链表中查找匹配的键值对。

# 数据结构与算法

## 1. 常见的**排序算法**和其时间复杂度是什么？

| 冒泡  | 选择  | 插入  | 快速     | 归并     | 桶排序 |
| ----- | ----- | ----- | -------- | -------- | ------ |
| O(n2) | O(n2) | O(n2) | O(nlogn) | O(nlogn) | O(n)   |

<img src="C:\Users\Auly\AppData\Local\YNote\data\sunjerd@163.com\548c1580d9424bca9044bd7a0bf941b9\1605080561(1).png" alt="img" style="zoom:80%;" />

## 2. 某个排序算法（冒泡、选择、插入、归并、快排、桶排）是如何实现的？

### **冒泡排序**

 1、小的元素往前调或者把大的元素往后调； 2、比较是相邻的两个元素比较，交换也发生在这两个元素之间；

```c++
void BubbleSort(int arr[], int n)
{
    for (int j = n - 1; j > 0; j--) // 右边界
    {
        int flag = 0;
        for (int i = 0; i < j; i++)
        { // 一趟冒泡
            if (arr[i] > arr[i + 1])
            {
                int tmp = arr[i];
                arr[i] = arr[i + 1];
                arr[i + 1] = tmp;
                flag = 1; // 标识发生了交换
            }
        }
        if (flag == 0) // 全程无交换
            break;
    }
}
```

最好时间复杂度：T = O(n)（一开始就是顺序）；

最坏时间复杂度：T = O(n2)

对于数组和链表排序都适用，而其它排序算法不能适用链表；元素较少时效率比较高；稳定排序

### 选择排序 

1、从左到右遍历，每个位置选择当前元素最小的； 

2、在一趟选择中，如果一个元素比当前元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了； 

举个例子，序列5 8 5 2 9， 我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了； 

```c++
void SelectionSort(int arr[], int n) {
    for(int i = 0; i < n-1; i++) {
        int minposition = i;
        for(int j = i + 1; j < n; j++)
        {
            if(arr[j] < arr[minposition])     
                minposition = j;              
        }
        swap(arr[i],arr[minposition]);  //将未排序部分的最小元换到有序部分的最后位置
    }
} 
```

最坏时间复杂度：T = θ(n2)(θ既是上界也是下界)

不稳定排序

* **堆排序** 

对选择排序时间复杂度的改进。

1、是选择排序的一种； 2、堆的结构是节点i的孩子为2*i和2*i+1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点，是完全二叉树； 3、在一个长为n 的序列，堆排序的过程是从第n/2开始和其子节点共3个值选择最大(大顶堆)或者最小(小顶堆),这3个元素之间的选择当然不会破坏稳定性。但当为n /2-1, n/2-2, …1这些个父节点选择元素时，就会破坏稳定性。有可能第n/2个父节点交换把后面一个元素交换过去了，而第n/2-1个父节点把后面一个相同的元素没 有交换，那么这2个相同的元素之间的稳定性就被破坏了； 4、不稳定的排序算法。

```c++
//子函数PercDown解法1.从小到大排序
void PercDown(int array[], int i, int n)
{                        //最后结果就是大顶堆
  int parent = i;        //父节点下标
  int child = 2 * i + 1; //子节点下标
  while (child < n){
    if (array[child] < array[child + 1] && child + 1 < n){ 
      child++;//判断子节点那个大，大的与父节点比较
    }
    if (array[parent] < array[child]){//判断父节点是否小于子节点
      swap(array[parent], array[child]); //交换父节点和子节点
      parent = child;                    //子节点下标赋给父节点下标
    }
    child = child * 2 + 1; //换行，比较下面的父节点和子节点
  }
}
```

```c++
//子函数PercDown解法2.
void PercDown(int arr[], int i, int n)
{
  int left = 2 * i + 1;  // index的左子节点
  int right = 2 * i + 2; // index的右子节点

  int maxIdx = i;
  if (left < n && arr[left] > arr[maxIdx])
    maxIdx = left;
  if (right < n && arr[right] > arr[maxIdx])
    maxIdx = right;
  if (maxIdx != index)
  {
    swap(arr[maxIdx], arr[index]);
    PercDown(arr, maxIdx, n);
  }
}
```

```c++
void HeapSort(int arr[], int n)
{
  for (int i = n / 2; i >= 0; i--) //构建堆(从最后)
    PercDown(arr, i, n);           //i为根节点，n为当前堆的元素
  for (int i = n - 1; i > 0; i--)
  {
    swap(arr[0], arr[i]); //将当前最大数arr[0]放到最后位置上
    PercDown(arr, 0, i);  //以0为根节点，i为当前最大堆的个数
  }
}
```

定理：堆排序处理n个不同元素的随机排列的平均比较次数是 2nlogn-O(nloglogn)

平均时间复杂度： T = O(nlogn)；常数很大

不稳定排序

实际效果不如希尔排序

### **插入排序** 

类似打牌排序

1、已经有序序列的基础上，一次插入一个元素； 

2、想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置； 

3、如果碰见一个和插入元素相 等的，那么插入元素把想插入的元素放在相等元素的后面； 

4、相等元素的前后顺序没有改变。

```c++
void InsertSort(int arr[], int n)
{
    for (int i = 1; i < n; i++)
    {
        int tmp = arr[i]; // 摸下一张牌
        int j = i;
        for (; j > 0 && arr[j - 1] > tmp; j--)
            arr[j] = arr[j - 1]; // 移出空位
        arr[j] = tmp;            // 新牌落位
    }
}
```

最好时间复杂度：顺序T = O(n) ；

最坏时间复杂度：顺序T = O(n2)

稳定排序。

**例题**：给定初始序列{34, 8, 64, 51, 32, 21}，冒泡排序和插入排序需要多少次元素交换才能完成？

冒泡排序：

第一次扫描：8 34 51 32 21 64    (4次)   第二次扫描：8 34 32 21 51 64 （2次）

第三次扫描：8 32 21 34 51 64  （2次）第四次扫描：8 21 32 34 51 64 （1次）

共4+2+2+1=9次

插入排序：

第一次扫描：8 34 64 51 32 21 （1次） 第二次扫描：8 34 64 51 32 21  （0次）

第三次扫描：8 34 51 64 32 21 （1次） 第四次扫描：8 32 34 51 64 21  （3次）

第五次扫描：8 21 32 34 51 64  （4次）

共1+0+1+3+4=9次

逆序对：对于下标i < j，如果A[i] > A[j]，则称(i,j)是一对逆序对。

序列{34，8，64，51，32，21}中有9个逆序对。

定理：任意N个不同元素组成的序列平均具有N(N-1)/4逆序对。

任何仅以交换相邻两元素来排序的算法，其平均时间复杂度为O(n2)

* 希尔排序(shell)

利用插入排序的简单，同时克服插入排序只交换相邻两个元素的缺点  

 <img src="C:\Users\Auly\AppData\Roaming\Typora\typora-user-images\image-20240515175211820.png" alt="image-20240515175211820" style="zoom:80%;" />

1、按照不同步长对元素进行插入排序； 2、当刚开始元素很无序的时候，步长最大，所以插入排序的  元素个数很少，速度很快； 3、当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高； 4、所以，希尔排序的时间复杂度会比o(n^2)好一些，由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元 素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱； 5、不稳定的排序算法。

```c++
void ShellSort(int arr[],int n)
{
    for(int D = n/2; D > 0; D/=2){ //希尔增量序列
       for(int P = D; P < n; P++){ //插入排序
          int tmp = arr[P];
          int i;
          for(i = P; i >= D && arr[i-D] > tmp; i -= D)
             arr[i] = arr[i-D];
           arr[i] = tmp;
       }   
    }    
}
```

最坏时间复杂度：T = θ(N2)(θ既是上界也是下界);

不稳定排序

坏的例子：

| 1    | 9    | 2    | 10   | 3    | 11   | 4    | 12   | 5    | 13   | 6    | 14   | 7    | 15   | 8    | 16   |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |

8 - 间隔、4 - 间隔、2- 间隔都有序

增量元素不互质(没有公因子)

### **归并排序**

核心：有序子列的归并

如果两个子列一共有N个元素，则归并的时间复杂度是T = O(N)

1、把序列递归地分成短序列，递归出口的短序列只有1个元素(认为直接有序)或者2个序列(1次比较和交换),然后把各个有序的短序列合并成一个有序的长序列，不断合并直到原序列全部排好序；

2、合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性； 

3、稳定排序算法。

方法一：递归写法：

1. 有序子列的归并：

```c++
// [left, mid] [mid+1, right] 都已有序
void Merge(int arr[], int left, int mid, int right)
{
  	int n=right-left+1, i = left, j=mid+1, k=0; // 注意k的起始索引是0，不是left
    vector<int> tmp(n);
    while (i<=mid && j<=right)
    {
        if (arr[i] <= arr[j])
        	tmp[k++] = arr[i++];
        else
        	tmp[k++] = arr[j++];
    }
    while (i <= mid) //直接复制左边剩下的
    	tmp[k++] = arr[i++];
    while (j <= right) //直接复制右边剩下的
    	tmp[k++] = arr[j++];
    for (k = 0; k < n; k++)
    	arr[left+k] = tmp[k];
}

// [left, right]
void Msort(int arr[], int left, int right)
{
    if (left < right)
    {
        int mid = (left + right) / 2;
        Msort(arr, left, mid);               
        Msort(arr, mid + 1, right);   
        Merge(arr, left, mid, right);
    }
}
```

时间复杂度：T(N) = T(N/2)+T(N/2)+O(N) = O(NlogN)(强时间复杂度，任何时候都是O(NlogN)

额外空间复杂度：O(N)，数据多的话空间不够

稳定排序

方法二：迭代算法：

```c++
void mergeSort(int arr[], int len) {
    int *a = arr;
    int *b = new int[len];
    for (int seg = 1; seg < len; seg += seg) {
        for (int start = 0; start < len; start += seg + seg) {
            int low = start, mid = min(start + seg, len), high = min(start + seg + seg, len);
            int k = low;
            int start1 = low, end1 = mid;
            int start2 = mid, end2 = high;
            while (start1 < end1 && start2 < end2)
                b[k++] = a[start1] < a[start2] ? a[start1++] : a[start2++];
            while (start1 < end1)
                b[k++] = a[start1++];
            while (start2 < end2)
                b[k++] = a[start2++];
        }
        int *temp = a;
        a = b;
        b = temp;
    }
    if (a != arr) {
        for (int i = 0; i < len; i++)
            b[i] = a[i];
        b = a;
    }
    delete[] b;
}
```

平均复杂度、最坏时间复杂度：O(NlogN)；稳定排序

额外的空间复杂度：O(N)

### 快速排序 

与归并排序类似，都是分而治之。

1、从数列中取出一个数作为基准数（枢轴，pivot）。 

2、将数组进行划分(partition)，将比基准数大的元素都移至枢轴右边，将小于等于基准数的元素都移至枢轴左边。

3、再对左右的子区间重复第二步的划分操作，直至每个子区间只有一个元素。

数组划分：取头、中、尾的中位数

```c++
int partition(int arr[], int i, int j)
{
    int pivot = arr[i];
    while (i < j)
    {
        while (i<j && arr[j] >= pivot) // 先右边区，找右边第一个小于基准数的值
        	--j;
        arr[i] = arr[j];         
        while (i<j && arr[i] <= pivot) // 左边区，找左边第一个大于基准数的值
        	++i;
        arr[j] = arr[i];
    }
    arr[i] = pivot; 
  	return i;
}
```

```c++
void QuickSort(int arr[], int left, int right)
{
    if (left >= right)
    	return;
    int pivot = partition(arr, left, right);
    QuickSort(arr, left, pivot - 1);
    QuickSort(arr, pivot + 1, right);
}
//统一接口
void Quick_Sort(int arr[], int N)
{
  QuickSort(arr, 0, N);
}
```

容易写错；

最好时间复杂度：每次正好中分T(N)=O(NlogN)

最坏时间复杂度：令pivot=A[0],T(N)=O(N2)

不稳定排序； 适合大规模排序，小规模排序(N<100)不如插入排序快

每一次选中主元，一次性放到正确的位置上，以后再也不会移动

### 桶排序

```c++
//N是数组的长度，M是最大值的范围
void Bucket_Sort(int arr[], int N, int M)
{
  int count[M]; 
  memset(count, 0, M * sizeof(int)); // 将buckets中的所有数据都初始化为0。
  for (int i = 0; i < N; i++)
    count[arr[i]]++;
  for (int i = 0,j = 0; i < M; i++)
  {
    while ((count[i]--) > 0)
      arr[j++] = i;
  }
}
```

时间复杂度：T(N,M)=O(M+N)

如果M>>N的话，使用基数排序

* 基数排序

  桶排序的升级。

  1、按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位； 2、有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优 先级排序，最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前； 3、用于整数； 4、需要较多的存储空间； 5、基于分别排序，分别收集； 6、稳定排序算法。

  ```c++
  int maxbit(int arr[], int n)
  {
    int d = 1;
    for (int i = 0; i < n; i++)
    {
      int c = 1;
      int p = arr[i];
      while (p / 10)
      {
        p = p / 10;
        c++;
      }
      if (c > d)
        d = c;
    }
    return d;
  }
  void RadixSort(int arr[], int n)
  {
    int count[10];
    int tmp[10];
    int d = maxbit(arr, n);
    int r = 1;
    for (int i = 0; i < d; i++)
    {
  
      for (int i = 0; i < 10; i++) //装桶之前要先清桶
        count[i] = 0;
      for (i = 0; i < n; i++) //记录每个桶的记录数
      {
        int k = arr[i] / r;
        int q = k % 10;
        count[q]++;
      }
      for (i = 1; i < 10; i++) //计算位置
      {
        count[i] += count[i - 1];
        //cout<<count[i]<<" ";
      }
      for (int j = n - 1; j >= 0; j--)
      {
        int p = arr[j] / r;
        int s = p % 10;
        tmp[count[s] - 1] = arr[j];
        count[s]--;
        //cout<<data[j]<<" ";
      }
      for (i = 0; i < n; i++)
      {
        arr[i] = tmp[i];
        //cout<<tmp[i]<<" ";
      }
      //    cout<<endl;
      r = r * 10;
    }
  }
  ```

  时间复杂度：T=O(P(N+B))P是logB；额外空间复杂度：O(N+B)

  稳定排序

  次位优先LSD Least Significant Digit 和 主位优先MSD Most Significant Digit

  整数排序；多关键字排序

  

## 3. **栈**是一种怎么样的数据结构？符合什么原则？在什么应用场景下会使用到栈？

1、栈是一种只能在一端进行插入和删除操作的特殊线性表。

2、 它按照后进先出（LIFO）的原则存储数据，先进入的数据被压入栈底，最后的数据在栈顶，需要读数据的时候从栈顶开始弹出数据（最后一个数据被第一个读出来）。
2、栈的应用场景
(1) 子程序的调用：在跳往子程序前，会先将下个指令的地址存到堆栈中，直到子程序执行完后再将地址取出，以回到原来的程序中。
(2) 处理递归调用：和子程序的调用类似，只是除了储存下一个指令的地址外，也将参数、区域变量等数据存入堆栈中。
(3) 表达式的转换[中缀表达式转后缀表达式]与求值(实际解决)。

(4)括号匹配：栈可用于检查括号是否匹配。

(4) 二叉树的遍历。
(5) 图形的深度优先(depth一first)搜索法。

## 4. **队列**是一种怎么样的数据结构？符合什么原则？在什么应用场景下会使用到队列？

1. 先进先出(FIFO)的数据结构。元素按照进入的顺序排列，新元素被添加到队列的末尾，老元素则从队列的头部被移除。

2. 应用场景：

   广度优先搜索（BFS）：在图的广度优先遍历中，使用队列来存储待访问的节点；

   线程调度：多线程程序中，使用队列管理任务的执行顺序；

   消息传递：进程间通信中，使用队列传递消息。

## 7. **二叉树的前序、中序、后序遍历**是如何进行的？

- 前序遍历：根节点－> 左节点－> 右节点

- 中序遍历：左节点－> 根节点－> 右节点

- 后序遍历：左节点－> 右节点－> 根节点


## 8. 能否使用**递归和非递归**两种不同的方法来实现二叉树的三种DFS遍历？前：LC144 中：94 后：145

```c++
/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode() : val(0), left(nullptr), right(nullptr) {}
 *     TreeNode(int x) : val(x), left(nullptr), right(nullptr) {}
 *     TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {}
 * };
 */
```

### **递归实现**：

通过递归调用函数来实现深度优先搜索：

\* 前序遍历：LC

```c++
vector<int> nums;
vector<int> preorderTraversal(TreeNode* root)
{
    if (root)
    {
        nums.push_back(root->val);
        preorderTraversal(root->left);
        preorderTraversal(root->right);
    }
    return nums;
}
```

防止复制数组浪费空间，另写一个递归子函数：

```c++
void pre(TreeNode* root, vector<int>& nums)
{
    if (root)
    {
        nums.push_back(root->val);
        pre(root->left, nums);
        pre(root->right, nums);
    }
}
vector<int> preorderTraversal(TreeNode* root)
{
    vector<int> nums;
    return pre(root,nums);
    return nums;
}
```



\* 中序遍历：

```c++
vector<int> in(TreeNode* root, vector<int>& nums)
{
    if (root)
    {
        in(root->left, nums);
        nums.push_back(root->val);
        in(root->right, nums);
    }
    return nums;
}
vector<int> inorderTraversal(TreeNode* root)
{
    vector<int> nums;
    return in(root,nums);
    return nums;    
}
```

\* 后序遍历：

```c++
vector<int> nums;
vector<int> post(TreeNode* root, vector<int>& nums)
{
    if (root)
    {
        post(root->left,nums);        
        post(root->right,nums);
        nums.push_back(root->val);
    }
    return nums;
}
vector<int> postorderTraversal(TreeNode* root)
{
    vector<int> nums;
    return post(root,nums);
    return nums;       
}
```

时间复杂度：O(n)

空间复杂度：O(n)

### **迭代实现**：

使用栈来辅助实现深度优先搜索。 

\* 前序遍历：

初始化栈并将根节点入栈，循环(栈不为空)：

1. 出栈并访问当前节点。 

2. 若当前节点有右子节点，则将右子节点入栈。 

3. 若当前节点有左子节点，则将左子节点入栈。 

代码：

```c++
vector<int> preorderTraversal(TreeNode* root)
{
    if (!root)
        return {};
    stack<TreeNode*> sk;
    sk.push(root);
    vector<int> nums;
    while (!sk.empty())
    {
        TreeNode* cur = sk.top();
        nums.push_back(cur->val);
        sk.pop();
        if (cur->right)
        	sk.push(cur->right);
        if (cur->left)
            sk.push(cur->left);
    }
    return nums;
}
```



\* 中序遍历：左 - 根 - 右

初始化：结果数组；栈~~，将根节点压入栈~~；循环（根节点不为空或栈不为空）：

当前节点不为空：

​	左子节点入栈；当前节点切换为左子节点；

​	当栈不为空：不操作；

**当前节点**切换为栈顶节点；压入结果数组；出栈；

当前节点切换为右节点；

代码：

```c++
vector<int> inorderTraversal(TreeNode* root)
{
    if (!root)
        return {};
    vector<int> nums;
    stack<TreeNode*> sk;
    while (root || !sk.empty())
    {
        while (root)
        {
            sk.push(root);
            root=root->left;
        }
       	root=sk.top(); // 注意栈顶为root
        sk.pop();
        nums.push_back(root->val);
        root=root->right;
    }
    return nums;
}
```



\* 后序遍历：左右根

后序遍历可仿照前序遍历写，然后反转；

初始化：结果数组（结果数组为根右左，反转后即最终结果）；栈为空；循环（栈不为空或根节点不为空）：

初始化栈并将根节点入栈，循环(栈不为空)：

1. 出栈并访问当前节点。 

2. 若当前节点有左子节点，则将左子节点入栈。 

3. 若当前节点有右子节点，则将右子节点入栈。 

代码：

```c++
vector<int> postorderTraversal(TreeNode* root)
{
    if (!root)
        return {};
    vector<int> nums;
    stack<TreeNode*> sk;
    sk.push(root);
    while (!sk.empty())
    {
        TreeNode* cur=sk.top();
        sk.pop();
		nums.push_back(cur->val);
        if (cur->left)
            sk.push(cur->left);
        if (cur->right)
            sk.push(cur->right);
    }
    reverse(nums.begin(), nums.end());
    return nums;
}
```

时间复杂度：O(n)

空间复杂度：O(n)

## 9. 给定一棵二叉树的**前序遍历结果和中序遍历结果**，如何复原这棵二叉树？LC105

递归参数：输入参数：前序数组，中序数组；返回参数：根节点

递归终止条件：前序/中序数组为空，返回空

1. 前序数组第一位是根节点数值；初始化根节点；

2. 从中序数组找根节点值索引idx；

3. 切割中序数组：[左子树[0:idx]，根idx，右子树[idx+1:n-1]]；

4. 切割前序数组：[根0, 左子树[1:idx]，右子树[idx+1:n-1]]

5. 递归：左子树 = (前序左子树数组，中序左子树数组)

   ​	   右子树 = (前序右子树数组，中序右子树数组)

代码：

```c++
TreeNode* buildTree(vector<int>& preorder, vector<int>& inorder)
{
    if (preorder.empty())
        return nullptr;
    int val=preorder[0];
    TreeNode* root=new TreeNode(val);
    if (preorder.size()==1)
        return root;
    int idx=0;
    for (; idx<inorder.size() && inorder[idx]!=val; idx++){}
    vector<int> inLeft(inorder.begin(), inorder.begin()+idx); // 注意用数组初始化[)
    vector<int> inRight(inorder.begin()+idx+1, inorder.end());
    vector<int> preLeft(preorder.begin()+1, preorder.begin()+idx+1);
    vector<int> preRight(preorder.begin()+idx+1, preorder.end());
    root->left=buildTree(preLeft, inLeft); // 注意参数顺序
    root->right=buildTree(preRight, inRight);
    return root;
}
```



## 10. 给定一棵二叉树的**后序遍历结果和中序遍历结果**，如何复原这棵二叉树？LC106

这个本质上与上边的题目是一样的求解方法，只不过这里提供根节点信息的是后序遍历，后序遍历的最后一个节点就是根节点。

递归参数：输入参数：前序数组，中序数组；返回参数：根节点

递归终止条件：前序/中序数组为空，返回空

1. 前序数组第一位是根节点数值；初始化根节点；

2. 从中序数组找根节点值索引idx；

3. 切割中序数组：[左子树[0:idx]，根idx，右子树[idx+1:n-1]]；

4. 切割后序数组：[左子树[0:idx-1]，右子树[idx:n-2]，根n-1]；

5. 递归：左子树 = (中序左子树数组，后序左子树数组)

   ​	   右子树 = (中序右子树数组，后序右子树数组)

代码：

```c++
TreeNode* buildTree(vector<int>& inorder, vector<int>& postorder)
{
    if (inorder.empty())
        return nullptr;
    int val=postorder.back();
    TreeNode* root=new TreeNode(val);
    if (inorder.size()==1)
        return root;
    int idx=0;
    for (; idx<inorder.size() && inorder[idx]!=val; idx++){}
    vector<int> inLeft(inorder.begin(), inorder.begin()+idx); // 注意用数组初始化[)
    vector<int> inRight(inorder.begin()+idx+1, inorder.end());
    vector<int> postLeft(postorder.begin(), postorder.begin()+idx);
    vector<int> postRight(postorder.begin()+idx, postorder.end()-1);
    root->left=buildTree(inLeft, postLeft); // 注意参数顺序
    root->right=buildTree(inRight, postRight);
    return root;
}
```

## 11. **二叉树的层序遍历**是如何进行的？LC102

层序遍历就是按二叉树从上到下，从左到右依次打印每个节点中存储的数据。
　　实现方案的确很好想到，但是具体实现容易卡壳在你是将什么放入队列中。本人当时面试仅存储每个数据到队列中，造成访问完A，然后将B和C（左右孩子）放入队列，并且删除最前面一个数（当前也就是A），这样B就轮到了最前方。想着是依次下去，但是如果队列仅存数据就会发现，不知道后面如何顺序访问下去，也不知道二叉树何时停止。所以正确的方式是队列中每个节点应该是存储一个二叉树的指针，这样才能依次依靠指针left和right访问下去。

代码：

```c++
vector<vector<int>>levelOrder(TreeNode* root)
{
    vector<vector<int>> nums;
    if (!root)
        return nums;
    queue<TreeNode*> q; //定义一个队列，数据类型是二叉树指针，不要仅是int！！不然无法遍历
    q.push(root);
    while (!q.empty())
    {
        int size=q.size();
        vector<int> level;
        for (int i=0; i<size; i++)
        {
            TreeNode* cur = q.front();
            q.pop();
            level.push_back(cur->val);
            if (cur->left) 
            	q.push(cur->left);  
            if (cur->right)
            	q.push(cur->right);
        }
		nums.push_back(level);
    }
    return nums;
}
```

## 12. **二叉搜索树**是什么？

二叉搜索树是一种特殊的二叉树（每个节点最多拥有 2 个子节点），无论插入还是删除，它总是有序的

或是一颗空树，或是具有如下性质的二叉树：

(1) 若它的左子树不空，则 左子树 上所有结点的值 均小于它的根结点的值；

(2) 若它的右子树不空，则 右子树 上所有结点的值 均大于它的根结点的值；

(3) 它的 左、右子树又分别为二叉排序树 。

即中序遍历是有序的。

## 13. **堆**是一种怎么样的数据结构？在什么应用场景下会使用到堆？

堆是一个完全二叉树；

堆中的每一个节点的值都必须大于等于（大顶堆）or小于等于（小顶堆）其子树中的每个节点的值；

堆排序

如上已经讲解过了。

优先级队列

优先级队列中，数据的出队不是按照入队先后来决定的，而是按照优先级来的，优先级高（低）的就先出队，实现优先级队列的方法有很多，但是其中使用堆来实现是最为快捷高效的

## 14. **堆的底层原理**是怎么实现的？

将完全二叉树按照层次遍历的顺序存储在数组中。
- 对于大顶堆，任意节点在数组中的下标为 i，则其左子节点下标为 2i+1，右子节点下标为 2i+2。
- 对于小顶堆，节点下标计算方式相同，但节点的值小于等于其子节点的值。

## 15. **最小生成树**是什么？有哪两种经典算法？

一个连通图的生成树是图的一个极小连通子图,它包含所有顶点,但只有足以构成树的n-1条边
这意味着对生成树来说,砍去它的任何一条边,就会使生成树变成非连通图,若给他增加一条边就会形成一条回路
最小生成树:权值最小的那颗生成树叫~
最小生成树的性质:

最小生成树并不唯一,准确的来说是最小生成树的树形并不唯一
最小生成树的权值之和唯一,并且是最小的
最小生成树的边数=顶点数-1

求最小生成树有两种经典算法:普里姆算法(prim)和克鲁斯卡尔(kruskal)算法

不管是Kruskal算法还是Prim算法，都是**基于排序和贪心的算法**。

### 1. prim

Prim算法是基于**当前已连通集合的外延边权值排序的算法**。传统的Prim算法包含以下步骤

1. 根据边的数据，构建图的邻接表`neighbor_dic`，邻接表的`key`为节点编号，`value`为该节点所有邻接节点`nxt_node`以及构成的边的权值`Z`所构成的数组，以`(Z, nxt_node)`二元组的方式进行存储。
2. 选择任意一个点作为初始点`cur_node`，一般选择`cur_node = 0`或`cur_node = 1`。
3. 构建一个小根堆`heap`，用于储存若干待连接的边。在小根堆中，边权值`Z`更小的`(Z, nxt_node)`二元组会被储存在堆顶。
4. 构建一个集合`node_used`，用于储存若干已经连通的节点。
5. 从初始点`cur_node`出发，把起始点作为**已连通集合**的出发点。已连通集合不断往外扩散构建边，由于需要构建`n-1`条边，该过程直接在一个循环`n-1`次的`for`循环中进行。其具体过程如下
   1. 选择`cur_node`在邻接表`eighbor_dic[cur_node]`中的所有近邻点`nxt_node`，其构成的边的权值为`Z`。若
      1. 近邻点`nxt_node`已经出现在集合`node_used`中，说明该近邻点已经位于已连通集合中，直接跳过。
      2. 近邻点`nxt_node`尚未出现在集合`node_used`中，说明该近邻点尚未位于已连通集合中，将这条边以`(Z, nxt_node)`二元组的形式加入小根堆中。
   2. 当`cur_node`的所有近邻点以及构成的边都加入小根堆中之后，使用`while`循环反复考虑堆顶元素。若
      1. 堆为空，则堆顶元素不存在。退出`while`循环。
      2. 堆顶元素对应的外延节点`heap[0][1]`**已经位于已连通集合中**，则弹出堆顶元素，考虑下一个堆顶元素。
      3. 堆顶元素对应的外延节点`heap[0][1]`**尚未位于已连通集合中**，则这个节点**将成为当前已连通集合的下一个的外延节点**，退出`while`循环。
   3. 判断此时堆是否为空，如果堆为空，则无法继续外延，无法构建树。
   4. 此时堆顶元素`heap[0]`即为当前已连通集合的新的外延节点。需要
      1. 将该节点`heap[0][1]`对应的边权值`heap[0][0]`计入总权值`ans`中
      2. 将该节点`heap[0][1]`加入集合`node_used`，表示成为**已连通集合的一部分**。
      3. 将该节点`heap[0][1]`设置为新的`cur_node`，因为新加入的这个节点会带来更多的近邻点和边。

求最小生成树代码(粘贴即能跑)：

```c++
#include <iostream>
#include <stdlib.h>
#define maxSize 100
#define infinity 65535
using namespace std;
typedef struct{
    char vnode[maxSize];
    int edge[maxSize][maxSize];
    int n,e;
}MGraph; 

void createMGraph(MGraph &G){//邻接矩阵构造图 
    int i,j,n,e,k,w;
    cout<< "请输入图的顶点数和边数"<<endl;
    cin>> G.n >> G.e;
    n=G.n;
    e=G.e;
    cout<< "请输入顶点"<<endl;
    for(i=0;i<n;i++){
        cin>> G.vnode[i]; 
    }
    for(i=0;i<n;i++){
        for(j=0;j<n;j++){
            G.edge[i][j]=infinity;
        }
    }
    cout<< "请输入边的下标i,j"<<endl;
    for(k=0;k<e;k++){
        scanf("%d %d %d",&i,&j,&w);
        G.edge[i][j]=w;
        G.edge[j][i]=G.edge[i][j];
    } 
}

void minSpanTree_prim(MGraph G){//prim算法求最小生成树 
    int n,e,i,j,min,k,t;
    n=G.n;
    int lowcost[maxSize];//为0表示顶点加入最小生成树,其他存放边的权值 
    int adjvex[maxSize];//这个存放顶点下标,标明顶点是新增顶点,还是之前遍历过的顶点 
    lowcost[0]=0;//把首个顶点(下标为0的顶点)加入到最小生成树 
    adjvex[0]=0;//下标为0 
    for(i=1;i<n;i++){//循环0下标顶点与其他顶点的连接情况 (不从0开始是因为0 0表示自己和自己的环) 
        lowcost[i]=G.edge[0][i];//把0下标顶点和其他顶点组成的边的权值存放到lowcost数组中 
        adjvex[i]=0;//当前lowcost数组中的边的权值的起始顶点全部都是下标为0的顶点,而结束顶点则是序号为lowcost数组下标的顶点 
    }
    cout<<"最小生成树为:"<<endl; 
    for(t=1;t<n;t++){//循环所有顶点,构造最小生成树 
        min=infinity;//初始化min,刚开始为一个极大值 
        j=1;k=0;
        while(j<n){//遍历lowcost数组 
            if(lowcost[j]!=0&&lowcost[j]<min){//除去已加入最小生成树的顶点 
                min=lowcost[j];//找出lowcost数组中最小的权值,并赋值给min 
                k=j;//记录最小权值的下标 (这个k其实就是权值最小的那条边的结束顶点) 
            }
            j++;
        }
        printf("(%d,%d)\n",adjvex[k],k);//打印权值最小的那条边的起始顶点和结束顶点 
        lowcost[k]=0;//把k下标的顶点加入到最小生成树 
        for(i=1;i<n;i++){//遍历顶点 
            if(lowcost[i]!=0&&G.edge[k][i]<lowcost[i]){//要除去已加入最小生成树的顶点 
                lowcost[i]=G.edge[k][i];//在k结点与其他顶点邻接的权值和lowcost数组中取较小的一方更新lowcost 
                adjvex[i]=k;//记录较小权值的边的起始顶点下标 
            }
        }
    }
}
int main(int argc, char** argv) {
    MGraph G;
    createMGraph(G);
    minSpanTree_prim(G);
    return 0;
}
    /*
    示例输入:
        顶点数和边数: 9 15
        输入顶点:   0 1 2 3 4 5 6 7 8
        输入顶点下标和权值: 
                4 7 7
                2 8 8
                0 1 10
                0 5 11
                1 8 12
                3 7 16
                1 6 16
                5 6 17
                1 2 18
                6 7 19
                3 4 20
                3 8 21
                2 3 22
                3 6 24
                4 5 26
    */

```

2. kruskal算法

### 2. Kruskal算法

Kruskal算法是基于**所有边权值排序的算法**。传统的Kruskal算法包含以下步骤

1. 将所有边储存在数组`edges`中，并按照权重进行从小到大排序
2. 考虑排序后的每一条边，其权重为`Z`，所连接的节点分别为`X`和`Y`。若
   1. `X`和`Y`连接后不会形成环，即`X`和`Y`原本属于两个不同的连通块。则
      - 使用并查集将其并为同一个连通块，`union(X, Y)`
      - 这条权重为`Z`的边应该被选择，`ans += Z`
      - 此时树中的边数加`1`，即`edge_num += 1`
   2. `X`和`Y`连接后会形成环，即`X`和`Y`原本就属于同一个连通块。则‘
      - 跳过这条边，无需做其他计算。
3. 上述循环持续进行，直到边数`edge_num`等于`n-1`。

代码:

```c++
#include <iostream>
#include<algorithm>
#include<stdlib.h>
#define maxSize 100
#define infinity 65535
using namespace std;
typedef struct{//邻接矩阵构造的图结点 
    char vnode[maxSize];
    int edge[maxSize][maxSize];
    int n,e;
}MGraph; 

typedef struct{//边集结点(存放边的顶点下标和边的权重) 
    int start;//边起点 
    int end;//边终点 
    int w;//边权值 
}Road; 
Road road[maxSize];//边集数组
int parent[maxSize];
int getRoot(int i){//此函数用于找到下标为i的顶点在生成树中的父节点 (并查集) 
    while(parent[i]!=i){  
        i=parent[i];
    }
    return i;
}

bool compare(Road x,Road y){//自定义结构体比较方式,按结构体中的权值升序排 
    return x.w<y.w;
}

void createMGraph(MGraph &G){//创建图 
    int i,j,n,e,k,w;
    cout<< "请输入图的顶点数和边数"<<endl;
    cin>> G.n >> G.e;
    n=G.n;
    e=G.e;
    cout<< "请输入顶点"<<endl;
    for(i=0;i<n;i++){
        cin>> G.vnode[i]; 
    }
    for(i=0;i<n;i++){
        for(j=0;j<n;j++){
            G.edge[i][j]=infinity;
        }
    }
    cout<< "请输入边的下标i,j"<<endl;
    for(k=0;k<e;k++){
        scanf("%d %d %d",&i,&j,&w);
        G.edge[i][j]=w;
        road[k].start=i;//创建的时候就给边集数组赋值
        road[k].end=j;
        road[k].w=w;
        G.edge[j][i]=G.edge[i][j];//根据无向图邻接矩阵的对称性赋值
    } 
}

int kruskal(MGraph G){//克鲁斯卡尔算法 
    int a,b,sum=0;
    int e=G.e;
    for(int i=0;i<G.e;i++){//初始化根结点下标数组 
        parent[i]=i;//为存放根节点下标数组赋初值,自身作为自己的根节点 
    } 
    sort(road,road+e,compare);//按边集数组中的权值由小到大排序 
    for(int i=0;i<e;i++){//遍历已经排好序的边 
        a=getRoot(road[i].start);//获取开始顶点在生成树中的父节点
        b=getRoot(road[i].end);//获取终结顶点在生成树中的父节点
        if(a!=b){//当ab不等说明两者不是同一个父节点,不会构成环 
            parent[a]=b;//把b点作为孩子加在a的后面 
            printf("(%d,%d)\n",road[i].start,road[i].end);//打印构成最小生成树的边
            sum+=road[i].w;//最小生成树的权值总和
        }
    }
    printf("sum=%d\n",sum);
    return sum;
}
int main(int argc, char** argv) {
    MGraph G;
    createMGraph(G);
    kruskal(G);
    return 0;
}
/*
    示例输入:
        顶点数和边数: 9 15
        输入顶点:   0 1 2 3 4 5 6 7 8
        输入顶点下标和权值: 
                4 7 7
                2 8 8
                0 1 10
                0 5 11
                1 8 12
                3 7 16
                1 6 16
                5 6 17
                1 2 18
                6 7 19
                3 4 20
                3 8 21
                2 3 22
                3 6 24
                4 5 26
    */
```



## 16. **有向图和无向图**的区别与联系？

- 区别：

  有向图中的边具有方向性，表示一种单向关系；无向图中的边没有方向性，表示一种双向关系。

  有向图中的边是有序的，即从一个顶点指向另一个顶点；无向图中的边是无序的，表示连接两个顶点
  的关系。

- 联系：

  无向图可以看作是有向图的一种特殊情况，即有向图中每条单向边都可以拆成两条双向边。

  有向图和无向图都可以使用邻接表或邻接矩阵等方式来表示。

## 17. 表示图的方式有哪些？**邻接表、邻接矩阵、关联矩阵**的区别与联系？

邻接表、邻接矩阵、关联矩阵

邻接矩阵（**adjacency matrix**）是表示顶点之间相邻关系的二维数组。

可以看出邻接矩阵是在无向图的表示中是**转置矩阵**，而在有向图中则不是。

邻接链表（**adjacency list**）由图中的每一个结点及其相邻结点生成以该结点为头结点的一组链表。

邻接矩阵和邻接链表都是用来表示图中**各个点和每个点**之间的关系，而关联矩阵（**incidence matrix**）即用一个矩阵来表示**各个点和每条边**之间的关系。

它们的区别与联系如下：

* 区别：

1. 邻接表适用于表示稀疏图，节省空间；邻接矩阵适用于表示稠密图，能快速判断边的存在性。

2. 邻接表的查找某个顶点的所有邻接顶点的效率较高；邻接矩阵的查找效率较低，需要遍历一整行或一
   整列。

3. 关联矩阵可以同时表示顶点和边的关联关系，但占用的空间较大。

- 联系：

  邻接矩阵可以根据边的权重来表示带权图。

  邻接表和关联矩阵都能够表示有向图和无向图。

https://zhyjc6.github.io/posts/2020/03/11/%E5%9B%BE%E7%9A%84%E8%A1%A8%E7%A4%BA-%E5%85%B3%E8%81%94%E7%9F%A9%E9%98%B5-%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5-%E9%82%BB%E6%8E%A5%E9%93%BE%E8%A1%A8.html

## 18. **DFS和BFS**的区别与联系？

BFS（广度优先搜索）和DFS（深度优先搜索）是两种常见的图搜索算法，用于解决在图中查找特定节点或遍历整个图的问题。它们之间的区别如下所示：

1. 搜索方式：

   DFS：按照图的深度进行搜索，先访问离起始节点最远的节点。

   BFS：按照图的层级进行搜索，先访问离起始节点最近的节点。

2. 数据结构：

   DFS：使用栈（[Stack](https://www.volcengine.com/product/vestack)）作为辅助数据结构，将已访问的节点加入栈，并按照后进先出的方式进行访问。

   BFS：使用[队列](http://www.volcengine.com/product/Message-Queue-for-RabbitMQ)（[Queue](http://www.volcengine.com/product/Message-Queue-for-RabbitMQ)）作为辅助数据结构，将已访问的节点按照层级顺序加入[队列](http://www.volcengine.com/product/Message-Queue-for-RabbitMQ)，并按照先进先出的方式进行访问。

3. 搜索顺序：

   DFS：先访问起始节点，然后递归地访问其相邻节点，直到遇到没有未访问邻居的节点，然后返回上一层继续访问其他未访问的节点。

   BFS：先访问起始节点，然后按照层级顺序依次访问与之相邻的节点。

代码位于算法笔记中。

## 19. **DFS与栈**的关系是什么？

当我们递归地实现 `DFS` 时，似乎不需要使用任何栈。但实际上，我们使用的是由系统提供的隐式栈，也称为调用栈（Call Stack）

在DFS过程中，使用
栈来保存待访问的节点。具体步骤：
- 将起始节点入栈。
- 循环执行以下步骤，直到栈为空：
- 出栈并访问当前节点。
- 将当前节点的未访问过的邻接节点入栈。

## 20. **BFS与队列**的关系是什么？

在BFS过程中，使
用队列来保存待访问的节点。具体步骤：
- 将起始节点入队。
- 循环执行以下步骤，直到队列为空：
- 出队并访问当前节点。
- 将当前节点的未访问过的邻接节点入队。

## 21. **回溯与递归**的区别与联系？

区别：

回溯是一种通过尝试所有可能的结果来寻找解的算法思想。

递归是一种通过将问题分解为子问题来解决的算法思想。

联系：

回溯算法通常使用递归的方式实现，通过不断地尝试和回退来搜索解空间。

递归算法可以用于解决各种问题，包括回溯、动态规划、树的遍历等。

## 22. **动态规划与递归**的联系？

动态规划可以使用递归的方式实
现。在实际应用中，动态规划通常通过递归加上记忆化技术来实现，
以避免重复计算。具体步骤如下：

- 定义状态：将原问题划分为子问题，并定义状态以表示子问题的解。
- 定义状态转移方程：根据子问题之间的关系，定义状态之间的转移方式。
- 添加记忆化：使用数组、哈希表等数据结构来存储已计算的结果，避免重复计算。
- 自底向上计算：根据状态转移方程以自底向上的顺序计算结果。

## 23. 请设计一个**增删改查的时间复杂度均为O(1)**的数据结构

元素重复、元素不重复

可以使用哈希表和双向链表的结合来实现。

使用哈希表（HashMap）存储键值对，实现 O(1) 的查找操作。使用双向链表（Doubly Linked List）存储元素的插入和删除顺序，实现 O(1) 的插入和删除操作。

- 在哈希表的值中存储指向双向链表节点的指针。
- 在插入操作时，同时在哈希表中插入键值对，并在双向链表尾部插入新节点。
- 在删除操作时，通过哈希表查找节点并在双向链表中删除对应节点。
- 在查找操作时，通过哈希表查找节点并返回对应值。

类似LC380 插入删除获取随机值O(1)

# 计算机网络

## 1. 什么是ISO七层模型？

通过七个层次化的结构模型使不同的系统、不同的网络之间实现可靠的通讯。

（1）应用层

应用层：就是应用软件使用的协议，如邮箱使用的POP3，SMTP、远程登录使用的Telnet、获取IP地址的DHCP、域名解析的DNS、网页浏览的http协议等；这部分协议主要是规定应用软件如何去进行通信的。

（2）表示层

表示层：决定数据的展现（编码）形式，如同一部电影可以采样、量化、编码为RMVB、AVI，一张图片能够是JPEG、BMP、PNG等。

（3）会话层

会话层：为两端通信实体建立连接（会话），中间有认证鉴权以及检查点记录（供会话意外中断的时候可以继续，类似断点续传）。

（4）传输层

传输层：将一个数据/文件斩件分成很多小段，标记顺序以被对端接收后可以按顺序重组数据，另外标记该应用程序使用的端口号及提供QOS。（不同的应用程序使用不同计算机的端口号，同样的应用程序需要使用一样的端口号才能正常通信）

（5）网络层

网络层：路由选路，选择本次通信使用的协议（http、ftp等），指定路由策略及访问控制策略。（IP地址在这一层）

（6）数据链路层

数据链路层：根据端口与MAC地址，做分组（VLAN）隔离、端口安全、访问控制。（MAC地址在这一层）处理VLAN内的数据帧转发，跨VLAN间的访问，需要上升到网络层。

（7）物理层

物理层：将数据最终编码为用0、1标识的比特流，然后传输。（例如将题主头像的图片，变为一串01100111100这样的数字来表示）。

![img](C:\Users\Auly\AppData\Local\YNote\data\sunjerd@163.com\5af5d10a0b804c30b9cdc473350945f0\0_1325744597wm32.gif)                               

\- 下列协议属于OSI网络模型数据链路层的是

A. ==RARP==  B. SMTP  C.ICMP  D.UDP

\- 在通过浏览器访问一个网站（如百度）时会用到哪些协议 山石网科

==DNS，UDP, HTTP，TCP，IP，ARP，ICMP==

DNS协议获取网络地址，即IP地址；应用层使用了http协议进行超文本传输，对于服务器后台处理应该有telnet远程调用协议响应用户，打开网页，网页显示用到了表示层的HTML协议；

另外必然用到了传输层的TCP和网络层的IP协议；网络层ARP协议获取物理地址；ICMP协议控制信息的传递。

\- URL的一般形式是：<协议>://<主机>:<端口>/<路径>  

http端口不显示，默认是80。

网站的标识：不同的端口，不同IP地址，使用主机头（域名）

\- 浏览器输入一个URL发生了什么？

1.DNS解析。浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址;

2.TCP连接。解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接;

3.浏览器发送http请求。浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器;

4.服务器处理请求。服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器;

5.返回响应结果；

6.关闭TCP连接

7.浏览器解析HTML; 　

8.浏览器布局渲染。

$\textcolor{red}{传输层协议}$

\- 在一个信道上的同一时刻，能够进行双向数据传输的通信方式是==全双工==

\- TCP实现流量控制和拥塞控制，采用的方式是  

 A.预约缓冲区法  B.==滑动窗口技术==  C.丢弃分组法  D.许可证法  

\- 下列关于TCP的描述，正确的是  

A.面向报文 B.==传输层协议== C.==可靠== D.==面向连接== 

## 2. 什么是TCP/IP四层模型？

**TCP/IP**网络模型适用于不同设备上进程间的通信，共分为四层，从上到下分别是应用层、传输层、网络层、网络接口层。

<img src="C:\Users\Auly\AppData\Roaming\Typora\typora-user-images\image-20240521175129862.png" alt="image-20240521175129862" style="zoom:50%;" />

**应用层（Application Layer）**

应用层是最上层的，我们能直接接触到的层，我们日常所使用的软件都是在应用层上实现的。

应用层不关心数据是如何传输的，就和我们寄快递的时候只需要把包裹交给快递员，我们不关心包裹是如何运输的。

协议：应用层的协议包括HTTP、FTP、Telnet、DNS、SMTP等。



**传输层（Transport Layer）**

传输层是为应用层提供网络支持的，在传输层有两个传输协议，分别是TCP和UDP。

**TCP**（Transmission Control Protocol）

TCP的全称是传输控制协议，大部分应用传输层协议使用的都是TCP，**TCP为了保证数据能够可靠的传输到目的地，有流量控制、超时重传、拥塞控制等特性。**

**UDP**（User Datagram Protocol）

UDP全称是用户报文协议，UDP相对TCP来说就很简单，**只负责发送数据包，至于数据包能否正常抵达目的地，UDP不能保证；**但是换一个角度来说，UDP少干了这么多，那他的实时性相对TCP来说更好，**传输效率也更高。**

通常来说一台设备上会运行多个应用进程，为了区分数据要发送的具体进程，传输层中需要指定端口号来区分不同的进程和应用。

 

**网络层（Internet Layer）**

负责将数据从一个设备发送到另一个设备的并不是传输层，传输层设计的理念是，简单、高效、专注，实际场景中的网络环节错综复杂，网络层就来是负责数据实际传输。

网络层最常用的是IP协议（Internet Protocol），IP协议会将传输层的报文作为数据部分，再加上IP数据包组装成IP报文。

网络层负责将数据从一个设备传输到另一个设备，而为了确定目标设备，网络层需要有区分设备单的编号，这个编号就是IP地址。

对于IPv4协议，IP地址共32位（32个bit），共分成四段（例如：192.168.1.1），每段8位。如果只有单纯的IP地址，虽然做到了设备区分，但是殉职起来就特别麻烦，世界上那么多设备，一个个去匹配显然是非常不科学的。

因此需要借助子网掩码来将IP地址分为两种意义：

一个是网络号，负责标识IP地址是属于哪一个[子网]的；

一个是主机号，负责标识同一子网下的不同主机；

举个栗子，比如192.168.1.1/24，后面的/24表示的就是子网掩码255.255.255.0，255.255.255.0 二进制是「11111111-11111111-11111111-00000000」，其中共有24个1，为了简化子网掩码的表示，就用/24来代替。

网络号=IP地址按位与子网掩码

主机号=IP地址按位与子网掩码取反

 

**网络接口层（Link Layer）**

网络层生成完IP头部之后，接下来要交给网络接口层在IP头前面加上MAC头，并封装成数据帧（Data Frame）发送到网络上。

IP头中的接收方IP表示网络包的目的地，通过这个地址我们就可以判断要将包发送到那里，但是在以太网的世界中，这个思路行不通！

 以太网：

以太网是一种在局域网内，把附近的设备连接起来，使其可以互相通讯的技术。我们电脑上的以太网口、WiFi接口，以太网交换机、路由器上的千兆、万兆网口，还有网线，都是以太网的组成部分。

以太网判断网络包目的地的方式和IP不同，不需要采用互相匹配的方式才能在以太网中将包发往目的地，而MAC头就是干这个用的，所以在以太网进行通讯需要用到MAC地址。

MAC头是以太网使用的头，包含了发送方和接收方的MAC地址等信息，我们可以通过ARP协议获取对方的MAC地址。

所以网络接口层主要为网络提供链路级别的传输服务，负责在以太网、WiFi这样的底层网络上发送原始数据包，工作在网卡这个层次，使用MAC地址来别试网络中的设备。 

## 3. 什么是TCP/IP五层模型？

<img src="C:\Users\Auly\AppData\Roaming\Typora\typora-user-images\image-20240521175540043.png" alt="image-20240521175540043" style="zoom:67%;" />

**1**、实体层

​    把电脑连接起来的物理手段，比如用光缆、电缆、双绞线，它主要规定了网络的一些电器特性，负责传送0和1的电信号。

**2**、链路层

​    硬件上的范畴均在链路层的作用范围之内。规定了0和1的解读方式：比如多少个信号算一组，每个信号为有什么意义，这就是链接层的功能

**3**、网络层

​    网络层用来处理在网络上流动的数据包。数据包是网络传输的最小数据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计算机，并把数据包传送给对方。如果两台主机在不同的子网络，广播是传不过去的，只能通过路由的方式发送。这就导致了网络层的诞生，网络层出现后每台计算机就有了两个地址，一种是MAC地址，一种是网络地址，两者没有联系，MAC是绑定在网卡上的，网络地址是管理员分配的

**4**、传输层

​    有了MAC地址和IP地址，我们就可以在互联网上任意两台主机上建立通信端口传来数据包，通过端口给特定的程序来使用。

​    传输层的功能，就是建立端口到端口的通信，相比之下，网络层的功能是建立主机到主机的通信，只要确定主机和端口，就能就能实现程序间的交流。因此，UNIX系统就把主机+端口叫作“套接字“，有了它，就可以进行网络应用程序开发。

**5**、应用层

​    应用层决定了向用户提供应用服务时通信的活动。

​    TCP/IP协议族内预存了各类通用的应用服务，比如FTP和DNS服务就是其中两类，HTTP协议也处于该层。

​     应用程序收到传输层的数据，就要进行解读，其作用就是规定应用程序的数据格式。

​    举例来说TCP协议可以为各种各样的程序传递数据，比如Email等，那么必须有不同协议规定电子邮件等格式，这些应用程序协议就构成了应用层。

## 4. TCP协议和UDP协议的区别和联系？

1. TCP面向连接，TCP在收发数据之前，必须先和对方建立连接；UDP是无连接的。所谓的“连接”，其实是客户端和服务器的内存里保存的一份关于对方的信息，如ip地址、端口号等。

2. TCP提供可靠的服务。TCP保证数据正确性，UDP可能丢包；TCP保证数据顺序，UDP不保证。

3. TCP面向字节流；UDP是面向报文的。TCP可以看成是一种字节流，它会处理IP层或以下的层的丢包、重复以及错误问题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放在TCP头部。

4. 每一条TCP连接只能是点到点的；UDP支持一对一，一对多，多对一和多对多的交互通信。

5. TCP是全双工的的可靠信道，UDP是不可靠信道。

6. TCP对系统资源的要求较多，UDP对系统资源的要求较少。

\- TCP和UDP使用场景

TCP：在对可靠性要求较高的情况下，可以使用 TCP，即不考虑 UDP 的时候，都可以选择 TCP。例如：文件传输、接受邮件、远程登陆。

UDP：UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务，随时都可以发送数据，处理简单且高效。例如：包总量较小的通信（DNS、SNMP）；视频、音频等多媒体通信（即时通信），QQ就是使用的UDP；协议广播通信。主要是一切追求速度的场景上

TCP 的建立连接称为三次握手；TCP 的断开连接称为四次挥手

## 5. HTTP 与 HTTPS 的区别和联系？

**HTTP**（Hypertext Transfer Protocol）和 HTTPS（HTTP Secure）都是用于在 Web 应用程序中传输数据的协议，它们之间的主要区别在于安全性和加密方式。

1、HTTP（http->tcp）：

HTTP 是一种基于文本的协议，它**使用明文传输数据，不具备加密和认证功能**。因此，HTTP 通信过程中的数据容易被窃听、篡改和伪造。

HTTP 协议的通信过程如下：

客户端向服务器发送请求报文。

服务器接收到请求报文后，返回响应报文。

客户端接收到响应报文后，解析数据并显示在浏览器中。

HTTP 协议的优点是简单、快速，适合传输一些不敏感的数据，如普通的网页、图片等。

2、HTTPS（http-> SSL/TLS->tcp）：

HTTPS 是 HTTP 协议的一种安全版本，**它使用 SSL 或 TLS 协议对传输的数据进行加密和认证，从而确保数据的安全性和完整性。**

HTTPS 的通信过程如下： 

客户端向服务器发送加密请求。

服务器接收到请求后，向客户端返回证书，证书中包含了服务器的公钥。

客户端使用公钥加密对称密钥，并将加密后的密钥发送给服务器。

服务器使用私钥解密对称密钥，并使用对称密钥对数据进行加密。

服务器将加密后的数据发送给客户端。

客户端使用对称密钥解密数据，并对数据进行验证和解析。

HTTPS 协议的优点是安全、可靠，适合传输一些敏感的数据，如密码、支付信息等。

3、区别：

安全性：HTTP 不具备加密和认证功能，数据容易被窃听、篡改和伪造，而 HTTPS 使用 SSL 或 TLS 协议对传输的数据进行加密和认证，从而确保数据的安全性和完整性。

传输速度：HTTPS 的加密和认证过程需要消耗更多的计算资源，因此传输速度比 HTTP 更慢。

端口号：HTTP 默认端口号为 80，而 HTTPS 默认端口号为 443。

4、联系：

通信过程：HTTP 和 HTTPS 的通信过程都是客户端向服务器发送请求，服务器返回响应的过程。

应用场景：HTTP 和 HTTPS 都可以用于在 Web 应用程序中传输数据，但 HTTPS 更适合传输敏感数据，如密码、支付信息等。

综上所述，HTTP 和 HTTPS 在安全性、传输速度和端口号等方面存在较大差异，因此在传输敏感数据时应优先选择 HTTPS 协议。同时，在一些不需要加密和认证的场景下，HTTP 协议可能更加适合。

## 6. HTTP请求的过程与原理

**HTTP**请求是指 ： 客户端通过发送 HTTP 请求向服务器请求对资源的访问。 它向服务器传递了一个数据块，也就是请求信息，HTTP 请求由三部分组成：请求行、请求头和请求正文。

工作原理：

1.由HTTP客户端发起一个请求，建立一个到服务器指定端口（默认是80端口）的TCP连接。 连接

2.HTTP服务器则在那个端口监听客户端发送过来的请求。一旦收到请求， 请求

3.服务器（向客户端）发回一个状态行，比如"HTTP/1.1 200 OK"，和（响应的）消息，消息的消息体可能是请求的文件、错误消息、或者其它一些信息。 响应

4.客户端接收服务器所返回的信息通过浏览器显示在用户的显示屏上，然后客 http工作流程图 http工作流程图 户机与服务器断开 连接

## 7. TCP协议的三次握手机制是怎么样的？为什么不能是两次或四次？

**TCP**（Transmission Control Protocol）的三次握手是建立一个TCP连接的过程。三次握手的过程如下：**

 **1.** **客户端向服务器发送连接请求（SYN）：** 客户端发送一个TCP报文，其中包含一个标志位 SYN（Synchronize Sequence Number），表示请求建立连接，并选择一个初始序列号（ISN）。

 **2.** **服务器响应连接请求（SYN-ACK）：** 服务器收到客户端的连接请求后，会发送一个TCP报文，其中包含 SYN 和 ACK（Acknowledgment）标志位。ACK 表示确认收到客户端的请求，而 SYN 表示服务器也同意建立连接，并选择自己的初始序列号。

 **3.** **客户端确认连接响应（ACK）：** 客户端收到服务器的 SYN-ACK 后，会发送一个带有 ACK 标志位的TCP报文，表示确认收到服务器的响应。这个报文不包含 SYN。

 完成了以上三个步骤，TCP连接就建立起来了。这个过程的三次握手是为了确保双方都能够正常接收和发送数据。

**为什么不能是两次或四次呢？**

**-** **不能是两次握手：** 如果只有两次握手，那么在第一次握手后，服务器就可以开始发送数据。但是客户端还不知道服务器是否同意建立连接，因此无法进行数据的可靠传输。如果第二次握手在某些情况下失败，服务器可能会浪费资源，因为它已经开始发送数据了。



1. 3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。

​     建立三次握手主要是因为A发送了再一次的确认，那么A为什么会再确认一次呢，主要是为了防止已失效的连接请求报文段又突然传送给B，从而产生了错误。

2.现在把三次握手改成仅需要两次握手，死锁是可能发生的。



**-** **不能是四次握手：** TCP的三次握手已经足够确保双方建立了可靠的连接。在正常情况下，只需要三次握手就能够满足建立连接的要求。四次握手将增加连接的关闭过程的复杂性，而且在正常情况下并不需要。在TCP中，两端只需明确表示建立连接和断开连接即可，不需要进行额外的确认。

 

TCP的三次握手是一种合理的设计，能够在网络中可靠地建立连接。通过三次握手，双方都能确保对方已经准备好进行数据的传输。

 

 

## 8. TCP协议的四次挥手机制是怎么样的？

TCP的四次挥手（Four-way handshake）是用于正常关闭一个TCP连接的过程。在数据传输结束后，当一方或双方决定关闭连接时，就会执行四次挥手的过程：

1. 第一次挥手（FIN1）： 主动关闭方（通常是客户端）发送一个带有 FIN（Finish）标志位的TCP报文给被动关闭方（通常是服务器），表示主动关闭方不再发送数据，但仍愿意接收数据。
2. 第二次挥手（ACK1）： 被动关闭方接收到第一次挥手后，发送一个带有 ACK 标志位的TCP报文作为确认。此时，被动关闭方进入半关闭状态，表示可以发送数据但不再接收数据。
3. 第三次挥手（FIN2）： 被动关闭方（通常是服务器）也准备关闭连接时，发送一个带有 FIN 标志位的TCP报文给主动关闭方。这表示被动关闭方不再发送数据，并请求主动关闭方关闭连接。
4. 第四次挥手（ACK2）： 主动关闭方接收到第三次挥手后，发送一个带有 ACK 标志位的TCP报文作为确认。此时，主动关闭方进入 TIME_WAIT 状态，等待一段时间以确保被动关闭方接收到确认，然后最终关闭连接。

通过这样的四次挥手过程，双方完成了连接的正常关闭。在最后一次 ACK 发送后，主动关闭方会进入 TIME_WAIT 状态，等待可能出现的延迟报文，确保连接的可靠关闭。

这四次挥手的设计是为了确保双方都能够正确地完成数据的传输和连接的关闭。在挥手过程中，主动关闭方和被动关闭方都有机会通知对方停止发送数据，最终完成连接的关闭。

## 9. 什么是TCP协议的粘包和拆包？

在socket通讯过程中，如果通讯的一端一次性连续发送多条数据包，tcp协议会将多个数据包打包成一个tcp报文发送出去，**这就是所谓的粘包。** 

而如果通讯的一端发送的数据包超过一次tcp报文所能传输的最大值时，就会将一个数据包拆成多个最大tcp长度的tcp报文分开传输，**这就叫做拆包。**

## 7.  什么是数字签名？什么是数字证书？

数字签名：

将 报文按双方约定的HASH 算法计算得到一个固定位数的 报文摘要。在 数学上保证：只要改动报文中任何一位，重新计算出的 报文摘要值就会与原先的值不相符。这样就保证了报文的不可更改性。

将该报文摘要值用发送者的私人密钥加密，然后连同原报文一起发送给接收者，而产生的报文即称数字签名

数字证书：

数字证书就是互联网通讯中标志通讯各方身份信息的一系列数据，提供了一种在Internet上验证您身份的方式，其作用类似于司机的驾驶执照或日常生活中的身份证。它是由一个由权威机构-----CA机构，又称为证书授权（Certificate Authority）中心发行的，人们可以在网上用它来识别对方的身份。数字证书是一个经证书授权中心数字签名的包含公开密钥拥有者信息以及公开密钥的文件。最简单的证书包含一个公开密钥、名称以及证书授权中心的数字签名。

## 11.对称加密和非对称加密有什么区别和联系

**对称加密**的原理是数据发送方将明文（原始数据）和加密密钥一起经过特殊加密算法处理后，使其变成复杂的加密密文发送出去。接收方收到密文后，若想解读原文，则需要使用加密密钥及相同算法的逆算法对密文进行解密，才能使其恢复成可读明文。

**非对称加密**的原理是甲方首先生成一对密钥同时将其中的一把作为公开密钥；得到公开密钥的乙方再使用该密钥对需要加密的信息进行加密后再发送给甲方；甲方再使用另一把对应的私有密钥对加密后的信息进行解密，这样就实现了机密数据传输。

 

对称加密和非对称加密的区别为：密钥不同、安全性不同、数字签名不同。

**一、密钥不同**1、对称加密：**对称加密加密和解密使用同一个密钥**。2、非对称加密：非对称加密**加密和解密所使用的不是同一个密钥，需要两个密钥来进行加密和解密**。

**二、安全性不同**1、**对称加密**：对称加密如果用于通过网络传输加密文件，那么不管使用任何方法将密钥告诉对方，**都有可能被窃听**。2、**非对称加密**：非对称加密因为它包含有两个密钥，且仅有其中的“公钥”是可以被公开的，接收方只需要使用自己已持有的私钥进行解密，这样就可以很好的避免密钥在传输过程中产生的安全问题。

三、数字签名不同1、对称加密：对称加密不可以用于数字签名和数字鉴别。2、非对称加密：非对称加密可以用于数字签名和数字鉴别。

## 12. 什么是Socket通信？

Socket通信是一种在计算机网络中实现进程间通信的一种方式。它使用网络上的套接字（Socket）来建立连接，使得不同计算机上的进程可以通过网络传输数据。Socket通信是一种基于网络的进程间通信机制，常用于实现客户端和服务器之间的通信。

基本概念和步骤：

1. 套接字（Socket）： 套接字是一种通信机制，允许不同计算机上的进程进行通信。在Socket通信中，通信的两端分别创建一个套接字，一个充当客户端，一个充当服务器。
2. 客户端（Client）： 客户端是发起连接请求的一方。它创建一个套接字，指定要连接的服务器的地址和端口，并发送连接请求。
3. 服务器端（Server）： 服务器端监听指定的端口，等待客户端的连接请求。一旦收到连接请求，就创建一个新的套接字，用于与客户端进行通信。
4. 连接建立： 服务器接受客户端的连接请求，建立一个全双工的通信通道。此时，客户端和服务器之间可以通过这个通道进行数据的发送和接收。
5. 数据传输： 一旦连接建立，客户端和服务器可以通过套接字进行双向的数据传输。数据可以是文本、二进制、图像等各种形式。
6. 连接关闭： 当通信结束时，可以通过关闭套接字来终止连接。关闭套接字后，连接的两端将不能再进行数据的传输。

**Socket****通信可以基于不同的传输层协议，包括TCP（Transmission Control Protocol）和UDP（User Datagram Protocol）。**TCP提供可靠的、面向连接的通信，适用于需要可靠性的场景，如文件传输、网页访问等。UDP是一种面向无连接的通信，适用于实时性要求较高、可以容忍一定丢失的场景，如音频、视频传输等。

总的来说，Socket通信是一种灵活且强大的机制，支持各种应用场景，从简单的局域网通信到复杂的互联网应用。

![image-20240521182618653](C:\Users\Auly\AppData\Roaming\Typora\typora-user-images\image-20240521182618653.png)

# 操作系统

## 1. 进程和线程有什么区别？

进程概念：

我们编译的代码可执行文件只是存储在硬盘里的静态文件，运行时加载到内存，CPU执行内存中的指令，这个运行的程序被称为进程。

进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；

线程概念：

线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组**，**指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等**），**打开的文件队列和其他内核资源。

区别：

1. 根本区别：进程是资源调度和分配的基本单位（打开文件、堆、金台区、代码段等），线程是CPU调度的基本单位（PC、状态码、通用寄存器、线程栈及栈指针）；

2. 从属关系不同：进程中包含了线程，线程属于进程。不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行；

3. 拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源.

4. 系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。

5. 控制和影响能力不同：子进程无法影响父进程，而子线程可以影响父线程，如果主线程发生异常会影响其所在进程和子线程。与进程相对应，线程与资源分配无关，它属于某一个进程，并与进程内的其他线程一起共享进程的资源。
6. CPU利用率不同：进程的CPU利用率较低，因为上下文切换开销较大，而线程的CPU的利用率较高，上下文的切换速度快。在多核或多CPU，或支持Hyper-threading的CPU上使用多线程程序设计的好处是显而易见，即提高了程序的执行吞吐率。在单CPU单核的计算机上，使用多线程技术，也可以把进程中负责I/O处理、人机交互而常被阻塞的部分与密集计算的部分分开来执行，编写专门的workhorse线程执行密集计算，从而提高了程序的执行效率。

## 2. 进程间通信的常见方式有哪些？

进程间通信（Inter-Process Communication，IPC）是指两个或多个独立运行的进程之间交换信息的机制。主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。

 1.  **管道（Pipe）：** 管道是一种半双工的通信机制，允许一个进程向另一个进程发送数据。管道可以是匿名的，也可以是具名的。匿名管道通常用于具有亲缘关系的进程之间的通信，而具名管道可用于非亲缘关系的进程。
 2.  **消息队列（Message Queues）**： 消息队列是一个存放在内核中的消息链表，它允许进程向其他进程发送消息。每个消息都有一个特定的类型，接收进程可以选择接收特定类型的消息。消息队列提供了一种异步的通信方式。
 3.  **共享内存（Shared Memory）：** 共享内存是一种让多个进程共享同一块物理内存区域的通信方式。进程可以通过读写共享内存来进行通信。由于没有内核的参与，共享内存通常是最快的 IPC 方法之一。
 4.  **信号（Signals）：** 信号是一种异步通信机制，用于通知进程某个事件已经发生。信号可以用于进程间的简单通信，例如通知进程中断或退出。常见的信号有SIGINT、SIGTERM等。
 5.  **信号量（Semaphores）：** 信号量是一种计数器，用于控制多个进程对共享资源的访问。它可以用于进程的同步和互斥。
 6.  **套接字（Sockets）**： 套接字是一种提供网络通信的通用机制，但它也可以在同一台计算机上的不同进程之间进行通信。本地套接字（Unix Domain Socket）是一种在同一台机器上的进程间通信的方式，比网络套接字更快。
 7.  **文件映射（Memory-mapped Files）：** 文件映射允许多个进程将同一个文件映射到它们的地址空间，从而实现对该文件的共享访问。它通常与共享内存结合使用。

### 线程程间通信的常见方式：

1. 临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
2.  互斥量：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 
3. 信号量：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。 
4. 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

## 3. 什么是死锁？

![image-20240521182642984](C:\Users\Auly\AppData\Roaming\Typora\typora-user-images\image-20240521182642984.png)

死锁”就是2个或2个以上的线程互相持有对方想要的资源，导致各自处于阻塞等待状态，致使程序无法执行下去，这就是“死锁”。

简单来说：一共有两个线程两把锁，T1线程拿到了A锁，T2拿到了B锁，但是T1还想要B锁，T2还像要A锁，谁也不释放锁，就会产生死锁 

两个线程两把锁，t1 和 t2 各自对 锁A 和 锁B 加锁，再尝试获取对方的锁。线程在竞争资源，导致死锁。

### 死锁的必要条件：

1. 互斥条件：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待。
2. 不剥夺条件：进程在所获得的资源未释放前，不能被其他进程强行夺走，只能自己释放。
3. 请求和保持条件：进程当前所拥有的资源在进程请求其他新资源时，由该进程继续占有。
4. 循环等待条件：存在一种进程资源循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。

## 4. 如何避免死锁？提供一些常见的死锁避免策略。

1. 鸵鸟算法：不考虑此问题，不理睬死锁问题；

不让死锁问题发生，分为两种：

2. 死锁预防

静态策略：设计合适的资源分配算法，来保证死锁的不发生；

在程序运行之前预防发生死锁。

（1）破坏互斥条件

例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

（2）破坏请求和保持条件

一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

（3）破坏不剥夺条件

允许抢占资源

（4）破坏循环请求等待

给资源统一编号，进程只能按编号顺序来请求资源。

3. 死锁避免

动态策略：以不让死锁发生为目标，跟踪并评估资源分配过程，根据评估结果决策是否分配

让死锁发生：

4. 死锁检测与解除

## 5. 什么是虚拟内存？它有什么作用？

虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存，而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

作用：

1. 缓存：将主存视为一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，高效使用了主存；
2. 内存管理：为每个进程提供了一致的地址空间，简化内存管理；
3. 内存保护：保护了每个进程的地址空间不被其他进程破坏。

系统只能从其他地方给你找点东西来临时代替内存， 而一般被拿来临时代替的就是硬盘。

## 6. 解释页式存储和分段存储的区别。

![image-20240521182657309](C:\Users\Auly\AppData\Roaming\Typora\typora-user-images\image-20240521182657309.png) 

分页是为了提高内存利用率，将内存分为一个个页框，将进程按照页框大小分为一个个页，分页对用户不可见。

分段则是按照程序的自身逻辑分配到内存中，对用户可见，用户编程时需要显示给出段名。并且分段比分页更容易实现信息的共享，因为页的大小是由页框决定，一个页中可能包含多个逻辑模块，令多个逻辑模块共享同一块内存显然是不合理的。

## 7. 什么是进程调度？列举一些常见的调度算法。

进程调度是操作系统的一种功能，用于决定当前应该运行哪个进程。它主要是根据一些策略和算法，从就绪队列中选择一个进程，将 CPU 的控制权转移到该进程，使其开始执行。

常用的进程调度算法有：

**高优先级优先调度算法**（Priority Scheduling）：按照进程的优先级来选择要运行的进程，优先级高的进程先运行。

**时间片轮转调度算法**（Round Robin Scheduling）：将所有就绪状态的进程放入一个队列中，每个进程被分配一个固定的时间片，当时间片用完后，操作系统会将该进程挂起，放回队列尾部，然后选择队列中的下一个进程继续运行。 

**最短作业优先调度算法**（Shortest Job First Scheduling）：按照进程的执行时间来选择要运行的进程，执行时间短的进程先运行。

## 8. 你对时间片轮转调度算法的了解是什么？

1、算法思想：公平地、轮流地为各个进程服务，让每个进程在一定时间间隔内得到响应。

2、算法规则：按照各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片，若进程未在一个时间片内执行完，则会剥夺处理机，将进程重新放到就绪队列队尾重新排队。

3、用于作业/进程调度：用于进程调度

4、是否可抢占：抢占式算法

5、是否会导致饥饿：不会

6、优缺点：

优点：公平，响应快，适用于分时操作系统。缺点：由于高频率的进程切换，因此有一定的开销，不区分任务的紧急程度

## 9. 解释文件系统的层次结构。

 ![image-20240521182707970](C:\Users\Auly\AppData\Roaming\Typora\typora-user-images\image-20240521182707970.png)

**用户接口：**文件系统需要向上层的用户提供一些简单易用的功能接口。这层就是用于处理用户发出的系统调用请求（Read、Write、Open、Close 等系统调用）。

**文件目录系统：**用户是通过文件路径来访问文件的，因此这一层需要根据用户给出的文件路径找到相应的FCB或索引结点。所有和目录、目录项相关的管理工作都在本层完成，如：管理活跃的文件目录表、管理打开文件表等。

**存取控制模块：**为了保证文件数据的安全，还需要验证用户是否有访问权限。这一层主要完成了文件保护相关功能。

**逻辑文件系统与文件信息缓冲区：**用户指明想要访问文件记录号，这一层需要将记录号转换为对应的逻辑地址。

**物理文件系统：**这一层需要把上一层提供的文件逻辑地址转换为实际的物理地址。

辅助分配模块：负责文件存储空间的管理，即负责分配和回收存储空间。

**设备管理模块：**直接与硬件交互，负责和硬件直接相关的一些管理工作。如：分配设备、分配设备缓冲区、磁盘调度、启动设备、释放设备等。

## 10. 什么是文件描述符？

Linux 中一切都可以看作文件，包括普通文件、链接文件、Socket 以及设备驱动等，对其进行相关操作时，都可能会创建对应的文件描述符。 

文件描述符（file descriptor）是内核为了高效管理已被打开的文件所创建的索引，用于指代被打开的文件，对文件所有 I/O 操作相关的系统调用都需要通过文件描述符。

## 11. 什么是同步和互斥？它们在多线程环境中的作用是什么？

同步：

是指散布在不同任务之间的若干程序片断，它们的运行必须严格按照规定的某种先后次序来运行，这种先后次序依赖于要完成的特定的任务。

最基本的场景就是：两个或两个以上的进程或线程在运行过程中协同步调，按预定的先后次序运行。比如 A 任务的运行依赖于 B 任务产生的数据。

互斥：

是指散布在不同任务之间的若干程序片断，当某个任务运行其中一个程序片段时，其它任务就不能运行它们之中的任一程序片段，只能等到该任务运行完这个程序片段后才可以运行。最基本的场景就是：一个公共资源同一时刻只能被一个进程或线程使用，多个进程或线程不能同时使用公共资源。

## 12. 列举一些同步机制和工具。

4种进程同步机制：

1.软件同步机制：使用编程方法解决临界区问题，有难度、具有局限性，现在很少采用。

2.硬件同步机制：使用特殊的硬件指令，可有效实现进程互斥。

3.信号量机制：一种有效的进程同步机制，已被广泛应用。

4.管程机制：新的进程同步机制

## 13. 中断和异常有何区别？

中断： 是指由于外部设备事件所引起的中断，如通常的磁盘中断、打印机中断等；

中断则是由于系统中某事件引起的，该事件与现行指令无关。



异常： 是指由于 CPU 内部事件所引起的中断，如程序出错(非法指令、地址越界)。

 异常是由于执行了现行指令所引起的。由于系统调用引起的中断属于异常。

## 14. 中断处理的流程是怎样的？

中断处理的基本过程包括中断请求、中断判优、中断响应、中断服务 和中断返回等五个阶段

## 15. 什么是页面置换算法？列举几种页面置换算法，并说明其工作原理。

在进程运行过程中，若需要访问的物理块不在内存中，就需要通过一定的方式来将页面载入内存，而此时内存很可能已无空闲空间，因此就需要一定的算法来选择内存中要被置换的页面，这种算法就被称为页面置换算法。

下面介绍几种常用的页面置换算法。

**最佳置换算法（OPT）：**该算法选择淘汰的页面是：未来永远不会再使用的页面 or 未来最长时间不再被访问的页面。该算法保证了可以获得最低缺页率，但无法预知未来页面的使用情况，因此目前无法实现，但通常用来评价其他算法。

**先入先出置换算法（FIFO）：**淘汰最先进入内存的页面,即选择在内存中驻留时间最久的页面予以淘汰。

**最近最久未使用置换算法（LRU）：**每次淘汰的页面是最近最久未使用的页面实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面。该算法的实现需要专门的

**时钟置换算法（CLOCK）**为每个页面设置一个访问位(访问位为1，表示最近访问过;访问位为0，表示最近没访问过)，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰一个页面时，只需检查页的访问位。如果是0，就选择该页换出;如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第一轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描（第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择一个淘汰页面最多会经过两轮扫描)。

**改进型的时钟置换算法**

简单的时钟置换算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过，就不需要执行I/O操作写回外存。只有被淘汰的页面被修改过时，才需要写回外存。

因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都相同时，应优先淘汰没有修改过的页面，避免I/O操作。这就是改进型的时钟置换算法的思想。修改位=0，表示页面没有被修改过;修改位=1，表示页面被修改过。

为方便讨论，用（访问位，修改位）的形式表示各页面状态。如（1，1）表示一个页面近期被访问过，且被修改过。

## 16. 进程线程协程

 ![image-20240521182730862](C:\Users\Auly\AppData\Roaming\Typora\typora-user-images\image-20240521182730862.png)

（1）进程：程序本身是没有生命周期的，它只是存在磁盘上的一些指令,程序一旦运行就是进程。

进程是-操作系统 提供的 抽象概念，是系统进行 资源分配和调度的 基本单位（出现线程以后，调度的基本单位就是线程），是操作系统结构的基础。程序是指令、数据及其组织形式的描述，进程是程序的实体。

 

（2）线程：是程序执行流的最小单元，是 处理器调度和分派的基本单位。一个进程可以有一个或多个线程，同一进程中的多个线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈和线程本地存储（如下图所示）。

 

（3）协程：协程（Coroutine，又称微线程）是一种 比线程更加轻量级 的存在，协程不是被操作系统内核所管理，而完全是由程序所控制。协程与线程以及进程的关系见下图所示。

**协程可以比作子程序，**但执行过程中，子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。协程之间的切换不需要涉及任何系统调用或任何阻塞调用。

**协程只在一个线程中执行，**子程序之间的切换发生在用户态上，而线程的阻塞状态是由操作系统内核来完成，发生在内核态上，因此协程相比线程节省线程创建和切换的开销。

**协程中不存在同时写变量冲突，**因此，也就不需要用守卫关键区块的同步性原语，比如互斥锁、信号量等，并且不需要来自操作系统的支持。

|          | 进程                                                         | 线程                                               | 协程                                                         |
| -------- | ------------------------------------------------------------ | -------------------------------------------------- | ------------------------------------------------------------ |
| 定义     | 资源分配和拥有的基本单位                                     | 程序执行的基本单位                                 | 用户态的轻量级线程，线程内部调度的基本单位                   |
| 切换情况 | 进程CPU环境(栈、寄存器、页表和文件句柄等)的保存以及新调度的进程CPU环境的设置 | 保存和设置程序计数器、少量寄存器和栈的内容         | 先将寄存器上下文和栈保存，等切换回来的时候再进行恢复         |
| 切换者   | 操作系统                                                     | 操作系统                                           | 用户                                                         |
| 切换过程 | 用户态->内核态->用户态                                       | 用户态->内核态->用户态                             | 用户态(没有陷入内核)                                         |
| 调用栈   | 内核栈                                                       | 内核栈                                             | 用户栈                                                       |
| 拥有资源 | CPU资源、内存资源、文件资源和句柄等                          | 程序计数器、寄存器、栈和状态字                     | 拥有自己的寄存器上下文和栈                                   |
| 并发性   | 不同进程之间切换实现并发，各自占有CPU实现并行                | 一个进程内部的多个线程并发执行                     | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 |
| 系统开销 | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 | 切换时只需保存和设置少量寄存器内容，因此开销很小   | 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 |
| 通信方面 | 进程间通信需要借助操作系统                                   | 线程间可以直接读写进程数据段(如全局变量)来进行通信 | 共享内存、消息队列                                           |